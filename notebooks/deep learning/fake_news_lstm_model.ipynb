{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvY9_0lgZcn1"
      },
      "source": [
        "## FAKE NEWS DETECTOR - LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBt4kgU3Zcn3"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXphvqEEZcn3",
        "outputId": "3bade751-8f42-4e50-d257-39e127f8c6b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.14)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n",
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2023.7.22)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "! pip3 install tensorflow\n",
        "! pip3 install keras\n",
        "! pip3 install nltk\n",
        "! pip3 install gensim\n",
        "! pip3 install scikit-learn\n",
        "! pip3 install keras-tuner\n",
        "! pip3 install keras_tuner\n",
        "\n",
        "#### Others\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "import re\n",
        "import nltk\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#### Scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier,LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "\n",
        "#### NLTK\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#### Tensorflow\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "\n",
        "#### Keras\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkUFDHkXZcn4"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Vg6Z8LNyZcn5"
      },
      "outputs": [],
      "source": [
        "DATA_BASE_PATH = \"./\"\n",
        "TRAIN_RATIO = 0.70\n",
        "TEST_RATIO = 0.30\n",
        "MAX_FEATURES_VECTORIZER= 500\n",
        "TRAINING_EPOCHS = 20 # Number of training epochs\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "VOCABULARY_SIZE = 5000 # the size of the vocabulary, indicating the maximum number of unique words that will be considered during the text embedding process.\n",
        "SENTENCE_LENGTH = 20 # the desired length of each sentence or text sequence after preprocessing. It indicates the number of words that will be included in each sequence.\n",
        "EMBEDDING_VECTOR_FEATURES = 40 # the number of dimensions in which each word will be represented in the embedding space. It determines the size of the word vectors generated, where words are mapped to continuous vector representations for machine learning tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad-2jHTjZcn5"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4BF519gZZcn5"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "train_data = pd.read_csv(DATA_BASE_PATH + 'train.csv')\n",
        "test_data = pd.read_csv(DATA_BASE_PATH + 'test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRkw6PnUZcn5"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWuxoeNGZcn5"
      },
      "source": [
        "The provided code snippet involves data preprocessing steps.\n",
        "\n",
        "First of all, we must remove the rows with missing values (NaN) from the train_data dataset.\n",
        "\n",
        "After dropping rows, the indices of the remaining rows may become non-contiguous by resetting the index of the DataFrame to ensure continuous and sequential indexing. This results in an updated DataFrame with a reset index, where the previous index values are moved to a new column, and a new sequential index is assigned to each row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RVsNVJf6Zcn6"
      },
      "outputs": [],
      "source": [
        "# Remove NaN\n",
        "train_data = train_data.dropna()\n",
        "train_data.reset_index(inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOSCDyEHZcn6"
      },
      "source": [
        "First step to continue preprocessing is to prepare input features and targe labels by creating two dataframes, one of them leaving only the input features for model training, and the other with the 'label' column is assigned to the variable y_train, representing the target labels corresponding to the input features in x_train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JQenETPLZcn6"
      },
      "outputs": [],
      "source": [
        "# Get target column (Y) and input features (X)\n",
        "x_train = train_data.drop('label',axis =1)\n",
        "y_train = train_data['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TVVPS85Zcn6"
      },
      "source": [
        "The provided code snippet initializes a PorterStemmer (from the Natural Language Toolkit (NLTK) library is initialized. The stemmer will be used to reduce words to their root form.) for text stemming and creates empty lists corpus and words. It iterates through each title in the DataFrame, removing non-alphanumeric characters, converting to lowercase, and splitting into words. The words are then stemmed and stopwords are removed, resulting in preprocessed sentences added to the corpus list and individual stemmed words to the words list. This process prepares the text data for analysis or model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5rF1Kdq5Zcn6"
      },
      "outputs": [],
      "source": [
        "# Stemming and preprocessing\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "words = []\n",
        "for i in range(0,len(train_data)):\n",
        "    review = re.sub('[^a-zA-Z0-9]',' ',train_data['title'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    statements = ' '.join(review)\n",
        "    corpus.append(statements)\n",
        "    words.append(review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRxhlY_2Zcn6"
      },
      "source": [
        "In the provided code, a copy of the training data x_train is assigned to the variable messages. The reset_index() method is then applied to the messages DataFrame. This method is often used to reset the index of a DataFrame, which means that the current index (usually numeric) is replaced with a default integer index starting from 0.\n",
        "\n",
        "By calling reset_index() with the inplace=True parameter, the operation modifies the DataFrame messages in place, without creating a new DataFrame. This can be useful when you want to apply changes directly to the existing DataFrame instead of creating a new copy.\n",
        "\n",
        "It's important to note that the specific impact of resetting the index depends on the structure and context of your data. In some cases, you might need to reset the index to make further manipulations or analyses easier, especially if the original index is not providing meaningful information. However, it's recommended to understand the implications of changing the index before applying it to your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c4el9yaBZcn7"
      },
      "outputs": [],
      "source": [
        "messages = x_train.copy()\n",
        "messages.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5JlGC-fZcn7"
      },
      "source": [
        "One-hot encoding is often used as a preprocessing step when working with natural language processing (NLP) tasks like text classification, including the detection of fake news using techniques like LSTM (Long Short-Term Memory) networks. LSTM networks are a type of recurrent neural network (RNN) that can effectively model sequences and patterns in sequential data like text.\n",
        "\n",
        "One-hot encoding is used with LSTM for the following reasons:\n",
        "\n",
        "- Input Representation: LSTM networks require input data to be in a numerical format. One-hot encoding converts words into numerical vectors, where each word is represented by a vector with all zeros except for a single \"1\" at the index corresponding to the word's position in the vocabulary. This allows text data to be fed into the network as numeric sequences.\n",
        "\n",
        "- Sparse Data Handling: NLP datasets typically have a large vocabulary, resulting in sparse data when using raw text representation. One-hot encoding reduces this sparsity by representing each word as a fixed-size vector. This can make training more efficient and reduce memory requirements.\n",
        "\n",
        "- Word Relationships: One-hot encoding treats each word as independent, which may not capture the semantic relationships between words. However, LSTM networks can learn contextual information from sequences of one-hot encoded vectors, allowing them to capture word relationships and dependencies within a text.\n",
        "\n",
        "- Sequence Modeling: LSTM networks excel at modeling sequences, and one-hot encoded vectors provide a suitable input format for sequential data. LSTM cells can maintain and update internal states that help capture longer-range dependencies in text.\n",
        "\n",
        "- Embedding Layer: In many cases, one-hot encoded vectors are further transformed using an embedding layer within the LSTM network. This layer learns dense representations (word embeddings) that capture semantic relationships between words. These learned embeddings can enhance the model's ability to understand the meaning and context of words.\n",
        "\n",
        "In the context of detecting fake news, one-hot encoding followed by LSTM modeling allows the network to learn patterns and relationships within the textual data, enabling the model to identify relevant features and make accurate predictions about the authenticity of news articles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS_c631tZcn7"
      },
      "source": [
        "The one_hot() function takes a word and a vocabulary size as input and returns a unique integer value for that word based on its position in the vocabulary. This technique is called one-hot encoding, where each word is represented by a vector with all values as zeros except for the position corresponding to the word's index in the vocabulary, which is set to 1.\n",
        "\n",
        "The resulting onehot_repr list contains one-hot encoded representations of words for each text document in the corpus. This representation is often used as an initial step before feeding the data into neural networks or other machine learning models for further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avXjvHAYZcn7",
        "outputId": "673171ce-fdd0-4e80-eaca-43d0dab28cfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[473, 3618, 1727, 4573, 2019, 2770, 3378, 3947, 1178, 3403],\n",
              " [8, 242, 3024, 242, 4759, 4993, 2314],\n",
              " [1187, 3959, 4580, 2571],\n",
              " [4446, 1609, 4673, 2916, 4588, 1159, 4028],\n",
              " [134, 4759, 3558, 772, 3983, 141, 4759, 3326, 218, 2563],\n",
              " [4393,\n",
              "  4642,\n",
              "  2184,\n",
              "  1437,\n",
              "  4369,\n",
              "  1876,\n",
              "  60,\n",
              "  1093,\n",
              "  2628,\n",
              "  1370,\n",
              "  2640,\n",
              "  1389,\n",
              "  4067,\n",
              "  4808,\n",
              "  2314],\n",
              " [659, 2187, 60, 4623, 1435, 1836, 2045, 2413, 2542, 579, 4691],\n",
              " [3334, 1245, 1129, 4616, 4057, 1509, 1876, 1398, 2542, 579, 4691],\n",
              " [1408, 2980, 2046, 1480, 4234, 4692, 2493, 4069, 1876, 3967],\n",
              " [3876, 2815, 2985, 4315, 4334, 3845, 4843, 880],\n",
              " [1062, 3124, 4024, 190, 175, 2550, 2377, 2600, 4022, 4111, 770],\n",
              " [4588, 3138, 2019, 4692, 1876, 4057],\n",
              " [3501, 4341, 3894, 113, 4432, 9, 4162, 3762, 2901],\n",
              " [4345, 136, 1691, 1668, 1971, 669, 2503, 2542, 579, 4691],\n",
              " [2917, 3997, 4435, 4484, 4414, 2542, 579, 4691],\n",
              " [1957, 3771, 4947, 1761, 3584, 4410, 1342, 1208, 2366, 4942, 2070, 2870],\n",
              " [1654, 1706, 242],\n",
              " [438, 543, 2229, 2924, 1876, 4137, 2490, 2314],\n",
              " [3430, 1591, 3024, 2498, 165, 546, 3487, 4703, 141],\n",
              " [86, 2854, 1876, 2269, 2691, 2314],\n",
              " [3336, 1715, 4877, 119, 412, 4649, 3487, 1727, 621, 3250, 2542, 579, 4691],\n",
              " [1101, 3302, 4747, 975, 197, 251, 4622],\n",
              " [4067, 2803, 2618, 1854, 1898, 1445, 756, 1216, 4709, 2655, 4680, 2314],\n",
              " [3816, 242, 2833, 2487, 4659, 1692, 4446, 336, 4469],\n",
              " [3421, 1258, 4280, 1113, 4534, 3211, 2498, 2889, 328, 2542, 579, 4691],\n",
              " [242, 3024, 452, 2864, 2542, 579, 4691],\n",
              " [438, 543, 2229, 1189, 4619, 4328, 1113, 2314],\n",
              " [3035, 1049, 4959, 2669, 2544, 2542, 579, 4691],\n",
              " [624, 3515, 535, 2360, 1319, 3758, 2942, 3160, 1583, 2542, 579, 4691],\n",
              " [3397, 435, 3320, 1216, 1571, 3060, 3960, 3951, 2777, 2542, 579, 4691],\n",
              " [4057, 242, 197, 4988, 2587, 128, 2542, 579, 4691],\n",
              " [4026, 2526, 2848, 4531, 3243, 2349],\n",
              " [595, 845, 3252, 3723, 4132, 4187],\n",
              " [2429, 3262, 1071, 2092, 2799, 875, 704, 2314],\n",
              " [4638, 3469, 4638, 126, 1806, 1006, 2542, 579, 4691],\n",
              " [2017, 370, 2628, 2965, 2168, 3705, 473, 1776, 2314],\n",
              " [684, 2696, 2069, 1424, 3766],\n",
              " [3420, 4403, 1845, 2732, 200, 1634, 2542, 579, 4691],\n",
              " [3819, 4350, 3076, 1580, 1408, 4657, 4144, 3277, 2314],\n",
              " [2483, 4656, 4679, 1163, 1558, 1337, 4280, 2542, 579, 4691],\n",
              " [4760, 2397, 2160, 4018, 1903, 349, 2400, 2941, 1587, 4808],\n",
              " [1762, 4638, 1336, 3142, 412, 158, 2542, 25, 2542, 579, 4691],\n",
              " [3985, 1898, 3424, 4075, 449, 3988, 912, 2486, 3328, 217, 4889, 2314],\n",
              " [762, 424, 3240],\n",
              " [250, 3144, 1034, 1892, 1539, 3742, 2112, 3113, 2833, 2314],\n",
              " [1876, 3723, 762, 49, 3549, 2533],\n",
              " [1264, 1103, 2199, 4548, 2997, 1411, 1503, 1947, 1871, 4443, 1883, 4808],\n",
              " [1559, 1693, 2803, 3937, 2647],\n",
              " [2924, 1876, 60, 3723, 2129, 3281, 4588, 4137, 3037],\n",
              " [3463, 2333, 908, 3273, 1991, 2542, 579, 4691],\n",
              " [4345, 905, 2316, 2942, 2468, 3801, 2542, 579, 4691],\n",
              " [2850, 4147, 3544, 3670, 3723],\n",
              " [1587, 3957, 2913, 111, 2762, 802, 3434, 3765, 2462, 2542, 579, 4691],\n",
              " [2258, 4657, 1876, 2180, 716, 3459, 3416, 3394, 2302],\n",
              " [2647, 671, 4145, 4549, 2599, 2416, 152, 2936, 1668, 2542, 579, 4691],\n",
              " [3252, 2552, 2803, 2618, 4137, 4689, 2316, 3252, 569],\n",
              " [2532, 1971, 1110, 1881, 2141, 3363, 1835, 3255, 2799, 1488],\n",
              " [3024, 4389, 813, 1654, 2767, 4510, 796, 242, 3024, 686],\n",
              " [1529, 623, 4657, 3336, 4469, 2542, 579, 4691],\n",
              " [644, 2889, 3340, 9, 1876, 1316, 4137, 873],\n",
              " [277, 1647, 1391, 2924],\n",
              " [2978, 1779, 1898, 2583, 1903],\n",
              " [1473, 3544, 4759, 1244, 2542, 579, 4691],\n",
              " [1208, 1605, 2479, 4026, 1460, 4214, 2542, 1288, 2542, 579, 4691],\n",
              " [4760, 931, 3967, 1408, 2552, 2506, 1619, 4144, 2542, 579, 4691],\n",
              " [2429, 3635, 443, 4976, 1492, 1148, 2542, 579, 4691],\n",
              " [2068, 3900, 3629, 1463, 1408, 481, 1450, 1113],\n",
              " [3321, 3252, 177, 4350, 2481, 4569, 4620, 2542, 579, 4691],\n",
              " [3185, 117, 1431, 2943, 1876, 3745, 142, 2314],\n",
              " [1453, 364, 1739, 3252, 2045, 4458, 1360, 4573, 3387, 2542, 579, 4691],\n",
              " [1587, 3236, 595, 4075, 4190, 2246, 3047, 4423, 415],\n",
              " [3985, 4549, 4908, 242],\n",
              " [2441, 1345, 2293, 4548, 4062, 3058, 4589, 1236, 2271],\n",
              " [1876, 424, 3062, 662, 2542, 579, 4691],\n",
              " [2142, 3937, 655, 269, 2837, 3633, 3221, 1782, 2542, 579, 4691],\n",
              " [2502],\n",
              " [1876, 1086, 4469, 4473, 1727, 1854, 2941, 2542, 579, 4691],\n",
              " [4280, 199, 1903, 4125, 4555, 3024, 4469, 1745, 1876, 2184, 1000, 3670],\n",
              " [4817, 772, 1240, 3238, 3991, 2542, 579, 4691],\n",
              " [3845, 4521, 2937, 544, 277, 1945, 2184, 1437, 2542, 579, 4691],\n",
              " [1825, 304, 3949, 1770, 4049, 2259, 1074, 430, 4293, 3075, 1548],\n",
              " [1494, 1723, 3611, 242, 1827, 1815, 3748, 1783, 2542, 579, 4691],\n",
              " [4524,\n",
              "  1923,\n",
              "  1636,\n",
              "  1517,\n",
              "  578,\n",
              "  2924,\n",
              "  1876,\n",
              "  2429,\n",
              "  3343,\n",
              "  4585,\n",
              "  2049,\n",
              "  559,\n",
              "  4946,\n",
              "  3853,\n",
              "  3547,\n",
              "  1784],\n",
              " [2314, 1113, 1391, 1876, 3526, 2314],\n",
              " [4021, 473, 610, 2961, 1590, 1408, 2369, 2329],\n",
              " [4201, 2540, 4889, 2429, 3563, 3723, 1784, 2314],\n",
              " [4075, 992, 422, 3670, 4869, 1995, 4877, 2542, 579, 4691],\n",
              " [862, 3252, 216, 3563, 3932, 1129, 3817, 2542, 579, 4691],\n",
              " [1160, 4315, 4562, 3302, 3734, 4914, 1080],\n",
              " [3487, 3742, 987, 2741, 1724, 2553, 2542, 579, 4691],\n",
              " [242, 3024, 2993, 1960, 4410, 2049, 4208, 1509, 2924, 1876, 2542, 579, 4691],\n",
              " [1876, 3465, 4055, 1903, 1729, 3985, 35, 935],\n",
              " [4721, 1148, 2467, 1062, 3894, 3705],\n",
              " [4394, 2965, 3857, 3003, 3003, 4942, 2070, 2870],\n",
              " [3417,\n",
              "  2618,\n",
              "  2759,\n",
              "  4394,\n",
              "  1562,\n",
              "  4973,\n",
              "  2498,\n",
              "  1882,\n",
              "  1689,\n",
              "  2759,\n",
              "  3399,\n",
              "  1562,\n",
              "  4840,\n",
              "  2498,\n",
              "  2314],\n",
              " [707, 242, 550, 1012, 1096, 1416, 624, 1389, 1472, 2314],\n",
              " [2258, 2005, 793, 2213, 1286, 296, 4629, 3826, 173, 3997, 2314],\n",
              " [303, 3728, 415, 546, 1176, 1061, 3390, 4622, 242, 370, 2542, 579, 4691],\n",
              " [3970, 4520, 1922, 2962, 1897, 1876, 4485, 3419, 4820, 2004],\n",
              " [2503,\n",
              "  1876,\n",
              "  1779,\n",
              "  4145,\n",
              "  2906,\n",
              "  4549,\n",
              "  3251,\n",
              "  2070,\n",
              "  1555,\n",
              "  102,\n",
              "  1761,\n",
              "  550,\n",
              "  1362,\n",
              "  3314],\n",
              " [383, 140, 2138, 1669, 4396, 1118, 3468, 170, 4919, 2542, 579, 4691],\n",
              " [3024, 4389, 4101, 431, 3328, 2248, 3138, 1815, 3670, 242, 2656, 1570],\n",
              " [2397, 2634, 3826, 4758, 3285, 3745, 2845, 1815, 2917, 3643, 1944, 2314],\n",
              " [1937, 2696, 1246, 559, 2019, 3751, 2354, 4575, 1444, 2542, 579, 4691],\n",
              " [2883, 846, 1727, 630, 1475, 2385, 2542, 579, 4691],\n",
              " [2647, 2672, 277, 4179, 4595, 1109, 2542, 579, 4691],\n",
              " [1876, 4112, 4300, 2132, 2550, 2096, 3138, 3340, 2542, 579, 4691],\n",
              " [2285, 4328, 2799, 686, 2367, 1580, 1408, 242, 686],\n",
              " [1214, 4924, 473, 2542, 3160, 3856, 1240, 2080, 4966, 4144, 968],\n",
              " [2121, 2208, 2388, 2426, 3320, 2121, 3246, 2542, 579, 4691],\n",
              " [3501, 4541, 1696, 473, 2955, 3075, 4010],\n",
              " [2342, 358, 1767, 3985, 4588, 3723, 475, 898, 242, 60],\n",
              " [822, 1875, 1034, 1029, 2764, 1094, 2542, 579, 4691],\n",
              " [1706, 1876, 2245, 3397, 2002, 3634, 388, 2542, 579, 4691],\n",
              " [2397, 40, 3805, 4021, 473, 4656, 2924, 1876, 2314],\n",
              " [514, 3547, 4659, 1876, 4145, 3671, 2941, 2314],\n",
              " [4740, 3598, 2913, 4072, 75],\n",
              " [270, 1876, 1113, 3705, 2308, 2542, 579, 4691],\n",
              " [2924, 1876, 158, 1129, 3410, 2008, 559, 1291, 2542, 579, 4691],\n",
              " [1638, 2429, 1291, 1472, 197, 3263, 471, 117, 3255, 2314],\n",
              " [3320, 4286, 2873, 4331],\n",
              " [3138, 364, 1739, 2913, 2696, 3912, 2542, 579, 4691],\n",
              " [2289, 2936, 4241, 4406, 430, 3406, 47, 3372, 529],\n",
              " [3252, 862, 752, 2552, 1778, 1176, 334, 856, 2490, 1727],\n",
              " [1876, 2863, 2567, 1936, 2521, 734, 3487, 2540, 3672, 3780, 4808],\n",
              " [1654, 1971, 3424, 2022, 242, 3024, 686, 4549, 4396],\n",
              " [1761, 3390, 3487, 3465, 4673, 3255, 373, 4620, 4460, 1651],\n",
              " [1903, 3251, 4158, 505, 1586, 4309, 3477, 1876, 3387],\n",
              " [277, 863, 3424, 3822, 166, 3051],\n",
              " [3751, 4673, 4394, 648, 1447, 1940, 877, 1708, 4689],\n",
              " [2669, 4734, 4276, 3838, 3718, 303, 4962, 3728, 2701, 2057, 3119],\n",
              " [2962, 4548, 3606, 691, 3807, 3505, 2180, 2694, 1407, 3807],\n",
              " [422, 4680, 2799, 4914, 1815, 3665, 4589, 455, 3468, 3670, 2477],\n",
              " [119, 1080, 1086, 1566, 2542, 579, 4691],\n",
              " [2793, 2420, 3417, 106, 1876, 2140, 2015, 2542, 579, 4691],\n",
              " [4396, 536, 3960, 3643, 2550, 1129, 4143, 2132, 2542, 579, 4691],\n",
              " [4161, 3156],\n",
              " [320, 2686, 4021, 473, 2146, 2418, 2033, 3741, 2542, 579, 4691],\n",
              " [86, 1286, 2571, 2943, 190, 2952, 1876, 189, 3403, 2314],\n",
              " [3024, 2516],\n",
              " [4668, 1884, 1447, 314, 3328, 4909, 691, 2542, 579, 4691],\n",
              " [3328, 4394, 4770, 2913, 1922, 4650],\n",
              " [2542, 250, 4692, 1534, 2956, 1128, 685, 3851, 1473],\n",
              " [2876, 796, 752, 1052],\n",
              " [4548, 1411, 1731, 2862, 2881, 1291, 1876],\n",
              " [939, 4657, 640, 4932, 1776, 4548, 1867, 209, 3960, 720, 2542, 579, 4691],\n",
              " [1150, 4435, 2476, 1553, 793, 2486, 2413, 2542, 579, 4691],\n",
              " [1812, 871, 4548, 3191, 2542, 579, 4691],\n",
              " [4882, 260, 1882, 1228, 3690, 841, 3035, 2314],\n",
              " [4612, 2167, 4286, 3948, 3748, 4283, 3487, 2498, 1488, 1708],\n",
              " [1319, 95, 4406, 557, 1473, 793, 2314],\n",
              " [401, 3780, 252, 4014, 1275, 1648],\n",
              " [1876, 3410, 2132, 3043, 3411, 4328, 3378, 4190, 1258],\n",
              " [1718,\n",
              "  2020,\n",
              "  872,\n",
              "  3424,\n",
              "  4799,\n",
              "  3008,\n",
              "  1205,\n",
              "  4657,\n",
              "  4144,\n",
              "  1616,\n",
              "  1927,\n",
              "  3340,\n",
              "  2129,\n",
              "  419,\n",
              "  2924,\n",
              "  1876,\n",
              "  2314],\n",
              " [1096, 2397, 2330, 3547, 3721, 2924, 1876, 4848, 2542, 579, 4691],\n",
              " [595, 3378, 1876, 2540, 357, 3544],\n",
              " [3932, 3255, 2942, 2522, 3265, 3334, 242, 557, 3455, 4036],\n",
              " [2526, 2599, 1808, 2659, 3233, 4190, 578, 2542, 579, 4691],\n",
              " [3544, 1582, 1582, 719, 2542, 579, 4691],\n",
              " [814, 3340, 846, 2149, 3627, 4793, 4072, 1702, 2542, 579, 4691],\n",
              " [19, 3894, 569, 451, 4620, 1836, 3455, 3252, 4057, 641, 2542, 579, 4691],\n",
              " [4593, 1458, 2571, 2513, 2022, 1433, 2345],\n",
              " [1616, 2304, 3584, 756, 1616, 2542, 579, 4691],\n",
              " [123, 2062, 3455, 473, 2941, 3723, 1876, 2542, 579, 4691],\n",
              " [4364, 3252, 3246, 3273, 277, 1052, 3075, 2571],\n",
              " [4025,\n",
              "  2088,\n",
              "  2049,\n",
              "  4600,\n",
              "  4580,\n",
              "  710,\n",
              "  166,\n",
              "  3034,\n",
              "  473,\n",
              "  2498,\n",
              "  1679,\n",
              "  4580,\n",
              "  85,\n",
              "  4160,\n",
              "  44,\n",
              "  2922,\n",
              "  669],\n",
              " [1503, 3273, 2049, 4396, 354, 568, 3334, 3251, 1562, 1012, 568],\n",
              " [550, 1876, 4649, 3829, 2542, 579, 4691],\n",
              " [1654, 2160, 2770, 1783, 2248, 3305, 3024],\n",
              " [2168, 1586, 402, 2865, 1860, 3350, 693, 4689],\n",
              " [218, 1333, 2618, 4444],\n",
              " [3932, 767, 3020, 956, 1034, 1912, 3805, 4673, 1194],\n",
              " [2924, 1876, 3648, 370, 3473, 1805, 3723, 4737, 2542, 579, 4691],\n",
              " [477, 2752, 2833, 3666, 4400, 330, 3885, 4720, 3477, 2542, 579, 4691],\n",
              " [4555, 1105, 1409, 1372, 2263, 4231, 2408, 4593],\n",
              " [2924, 1876, 4841, 1784, 2542, 579, 4691],\n",
              " [1228, 2542, 1548, 242, 2567, 4389, 3540, 2759, 4588, 2049, 3559, 349, 3086],\n",
              " [4067,\n",
              "  3410,\n",
              "  330,\n",
              "  3397,\n",
              "  3847,\n",
              "  4204,\n",
              "  1222,\n",
              "  1661,\n",
              "  3340,\n",
              "  3427,\n",
              "  1936,\n",
              "  3403,\n",
              "  4315,\n",
              "  722,\n",
              "  935],\n",
              " [1876, 4659, 1903, 1193, 1616, 4112, 2914, 2314],\n",
              " [4254, 2620, 1061, 684, 3390],\n",
              " [8, 2293, 4760, 2979, 734, 3731, 2542, 579, 4691],\n",
              " [3302, 1129, 3619, 1208, 4095, 3602, 2013],\n",
              " [1876, 4689, 1148, 1033, 3228, 3932, 2542, 579, 4691],\n",
              " [3024, 2847, 4964, 246, 686, 242, 3251, 424],\n",
              " [408, 4759, 1679, 3420, 728, 4144, 2314],\n",
              " [2924, 1876, 1071, 430, 1892],\n",
              " [3454, 2873, 4054, 3101, 2032, 4632, 2387, 1980, 2554],\n",
              " [1157, 1148, 4458, 574, 836, 1074, 3240, 95, 2542, 579, 4691],\n",
              " [4067, 2855, 3340, 303, 3728, 1437, 4468, 3334, 4280, 1113],\n",
              " [2503, 2418, 1408, 1089, 2900, 1661, 2497, 2681, 3670, 2542, 579, 4691],\n",
              " [4959, 1291, 2873, 4346, 922, 4793, 2604, 3050, 2542, 579, 4691],\n",
              " [2504, 3700, 2634, 1415, 4817, 1806, 1113, 1876],\n",
              " [2269,\n",
              "  1503,\n",
              "  3780,\n",
              "  3160,\n",
              "  3856,\n",
              "  1113,\n",
              "  1086,\n",
              "  1582,\n",
              "  898,\n",
              "  4057,\n",
              "  4580,\n",
              "  2070,\n",
              "  1249,\n",
              "  190],\n",
              " [4045, 3252, 3829, 4843, 2049, 2542, 579, 4691],\n",
              " [4286, 4258, 375, 2879, 1804, 2771, 4689, 2542, 579, 4691],\n",
              " [1963, 2429, 2728, 1689, 1974, 2873, 1876],\n",
              " [4396, 3259, 3960, 3643, 4793, 212, 2542, 579, 4691],\n",
              " [4057, 2207, 4689, 2603, 2174, 3340, 2409, 3745],\n",
              " [3637, 2943, 405, 248, 1539, 1584, 1165, 2542, 579, 4691],\n",
              " [4396, 3960, 1285, 3960, 3643, 4174, 1604, 3910, 2542, 579, 4691],\n",
              " [2794,\n",
              "  3785,\n",
              "  862,\n",
              "  2657,\n",
              "  549,\n",
              "  1338,\n",
              "  429,\n",
              "  2794,\n",
              "  1235,\n",
              "  2657,\n",
              "  549,\n",
              "  2018,\n",
              "  2124,\n",
              "  1641],\n",
              " [1876, 4196, 1113, 9, 2542, 1006, 4405, 1745, 2542, 579, 4691],\n",
              " [3252, 4226, 2481, 1404, 3099, 2669, 2542, 579, 4691],\n",
              " [3252, 630, 475, 1879, 443, 4689, 4530, 2542, 579, 3948, 624],\n",
              " [357, 541, 3424, 2545, 1864],\n",
              " [1903, 303, 3728, 3048, 1745, 370, 4370, 3410, 3985],\n",
              " [1183, 669, 443, 4793, 1631, 2208, 2542, 579, 4691],\n",
              " [4022,\n",
              "  1407,\n",
              "  3807,\n",
              "  1219,\n",
              "  1338,\n",
              "  4025,\n",
              "  1338,\n",
              "  662,\n",
              "  3807,\n",
              "  1876,\n",
              "  532,\n",
              "  1437,\n",
              "  1298,\n",
              "  4137,\n",
              "  2800],\n",
              " [2405, 1148, 2917, 3997, 4435, 1018, 4783, 2542, 579, 4691],\n",
              " [4940, 2405, 2182, 1625, 2229, 4328, 1113, 4259, 2314],\n",
              " [3020, 4187, 1709, 2542, 3119, 1876, 1783, 2542, 579, 4691],\n",
              " [1641, 4549, 1121, 4977, 4286, 1806, 4760, 2314],\n",
              " [1693, 812, 2943, 4632, 1359, 106, 2542, 579, 4691],\n",
              " [3160, 3387],\n",
              " [1324, 1860, 3252, 3767, 2082, 435, 2426, 4458, 3706, 2542, 579, 4691],\n",
              " [1876, 3410, 2759, 252, 2317, 1608, 2388, 2542, 579, 4691],\n",
              " [2049, 3487, 104, 3821, 1835, 3894, 4295, 4747, 2917, 2314],\n",
              " [2803, 2618, 1854, 4657, 1727, 239, 4415, 3363, 1708, 1488, 3948],\n",
              " [1641, 1903, 2873, 3960, 2894, 3544, 242, 2416, 1582, 2314],\n",
              " [2669, 1640, 3228, 610, 60, 19, 2280, 4291],\n",
              " [1015, 4171],\n",
              " [4623, 878, 2708, 1745, 1330, 3629, 212, 2542, 579, 4691],\n",
              " [1876, 2939, 1836, 2390, 2799, 4914, 2542, 579, 4691],\n",
              " [3976, 3565, 2175, 1574, 3723],\n",
              " [1338, 3103, 4570, 4820, 1450, 862, 922, 4220, 759, 4820, 1450, 862, 922],\n",
              " [565, 473, 574, 3716, 3109, 2542, 579, 4691],\n",
              " [461, 4369, 2376, 2924, 1876, 2542, 641, 3363, 2542, 579, 4691],\n",
              " [1923, 1636, 2580, 1854, 2924, 1876, 440, 248, 2542, 579, 4691],\n",
              " [2390, 2907, 4286, 3388, 4303, 3592, 2542, 579, 4691],\n",
              " [2927, 3412, 1786, 3252, 473, 3656, 1408, 2941],\n",
              " [3985, 4989, 1937, 1654, 983, 435],\n",
              " [2916, 661, 2662, 1295, 2848, 1815, 1072, 3020, 4691, 2542, 579, 4691],\n",
              " [1686, 4256, 2115, 4910, 2542, 384, 3706, 2314],\n",
              " [1876, 3047, 3714, 4445, 3959, 1012, 3146, 4198, 471, 2542, 579, 4691],\n",
              " [1433, 2833, 657, 2129, 1454, 2503, 1148, 1783, 3499, 3610, 4307, 898, 2314],\n",
              " [4983, 4970, 550, 2369, 3274, 3828, 2542, 579, 4691],\n",
              " [4777, 2962, 3334, 2280, 1693, 4509, 1619],\n",
              " [3273, 1727, 2899, 3487, 2229, 2542, 579, 4691],\n",
              " [2131, 4709, 1980, 892, 2366, 741, 2314],\n",
              " [684, 190, 1693, 2669],\n",
              " [2498, 354, 1183, 2304, 4908, 3328, 2147, 3263, 2789],\n",
              " [242, 4389, 171, 215, 3570, 4243, 203, 1654, 4204, 2167, 2943],\n",
              " [4026, 2833, 3120, 2889, 3606, 3015, 1876, 60],\n",
              " [1879, 2713, 3618, 4854, 4852, 2780, 1412, 1876, 2540, 2314],\n",
              " [2208, 3956, 3904, 3486, 1876, 4580, 2329],\n",
              " [2429, 4198, 3076, 1553, 2680, 628, 2314],\n",
              " [829,\n",
              "  4144,\n",
              "  1866,\n",
              "  4819,\n",
              "  3029,\n",
              "  595,\n",
              "  2571,\n",
              "  829,\n",
              "  4144,\n",
              "  229,\n",
              "  360,\n",
              "  3910,\n",
              "  3640,\n",
              "  3403],\n",
              " [2426, 3751, 4232, 242],\n",
              " [1093, 232, 887, 1696, 1755, 2988, 4932, 2542, 579, 4691],\n",
              " [3394, 4369, 4974, 1374, 2542, 579, 4691],\n",
              " [4287, 3463, 1616, 2791, 284, 1386, 2542, 579, 4691],\n",
              " [2913, 3826, 1231, 4203, 4585, 3255, 1155, 4335, 158, 3373],\n",
              " [174, 4458, 2628, 2955, 4580, 2390, 2542, 579, 4691],\n",
              " [812, 1876, 16, 620, 2669, 4588, 2941, 2914, 4057, 2314],\n",
              " [354, 4570, 669, 4580, 1809, 402],\n",
              " [2591, 4264, 1903, 248, 2540, 11, 3058, 1876],\n",
              " [3373, 4887, 4247, 1876, 4650, 1974, 685, 1473, 2542, 579, 4691],\n",
              " [4872, 3412, 1083, 3331, 4645, 2266, 3266, 809, 2542, 579, 4691],\n",
              " [1471, 888, 2408, 2542, 579, 4691],\n",
              " [930, 884, 4335, 1898, 4446, 550, 2542, 579, 4691],\n",
              " [4691, 2941, 1883, 2542, 579, 4691],\n",
              " [3252, 862, 4972, 3138, 117, 388, 3465, 4976, 4880, 2542, 579, 4691],\n",
              " [4806, 522, 4307, 4657, 2150, 3160, 3544, 2694],\n",
              " [4459, 413, 3956, 1360, 4588, 2030, 1298, 4673],\n",
              " [3623, 4125, 3732, 2876, 1932, 1406, 4446, 419, 2542, 579, 4691],\n",
              " [1876, 684, 591, 4877, 2092, 3076, 4345, 2970, 2314],\n",
              " [3414, 660, 2965, 2248, 4247, 486, 1876],\n",
              " [2868, 1876, 2388, 2941, 3906, 430, 856, 2542, 579, 4691],\n",
              " [4034, 4429, 1923, 4752, 3253, 2547, 2925, 3050],\n",
              " [4340, 694, 2897, 1291, 219, 2542, 579, 4691],\n",
              " [644, 2889, 4691, 2429, 4084, 3148, 2542, 579, 4691],\n",
              " [4340, 3255, 3947, 1876, 532, 194, 3104],\n",
              " [4057, 2035, 4051, 2000, 4998, 438, 4405, 1265, 2542, 579, 4691],\n",
              " [1049, 202, 1876, 1898, 3853, 662, 2542, 579, 4691],\n",
              " [2924, 1876, 2708, 2280, 3968, 1854],\n",
              " [2631, 3138, 1409, 1372, 2252, 3047, 1980, 1059, 2542, 579, 4691],\n",
              " [3898, 1298, 4896, 2913, 856, 3484, 3996],\n",
              " [3544, 277, 4941, 2696, 1295, 2542, 579, 4691],\n",
              " [1876, 2413, 4610, 3228, 4572, 4340, 2542, 579, 4691],\n",
              " [2176, 4687, 3468, 1904, 676, 3397, 1193, 3303],\n",
              " [2206, 4588, 3723],\n",
              " [2914, 2267, 1328, 4160, 4848, 756, 259, 2542, 579, 4691],\n",
              " [1695, 3929, 83, 3473, 2849, 1974, 1157, 4153, 1304, 4900, 3558, 2314],\n",
              " [2924, 1876, 536, 2466, 4469, 4271, 1473, 3292, 1716, 752, 2542, 579, 4691],\n",
              " [355, 2035, 4244, 4198, 4258, 2542, 579, 4691],\n",
              " [3747, 3819, 4419, 2618, 202, 4599, 2542, 579, 4691],\n",
              " [2924,\n",
              "  1876,\n",
              "  4659,\n",
              "  862,\n",
              "  4724,\n",
              "  242,\n",
              "  3024,\n",
              "  3734,\n",
              "  1590,\n",
              "  4307,\n",
              "  722,\n",
              "  2873,\n",
              "  4286,\n",
              "  2542,\n",
              "  579,\n",
              "  4691],\n",
              " [137, 790, 1876, 2554, 1360, 3387, 2542, 579, 4691],\n",
              " [1493, 3670, 4583, 1854, 3251, 424],\n",
              " [1876, 4389, 1037],\n",
              " [2429, 296, 2936, 3076, 610, 3273, 2314],\n",
              " [2503, 1113, 1719, 708, 409, 1548, 550, 1876, 2140, 206, 564, 4199, 1414],\n",
              " [2794, 1182, 4276, 1642, 2160, 4820, 2589],\n",
              " [174, 1030, 4116, 2993, 1808, 2913],\n",
              " [9, 418, 3465, 1368, 1343],\n",
              " [4647, 1706, 3838, 4986, 2250, 3047, 4026, 1418, 1703, 2116, 2542, 579, 4691],\n",
              " [2673, 242, 3024, 4585, 2314],\n",
              " [4304, 816, 277, 3684, 4846, 322, 1619, 1075, 106],\n",
              " [242, 1912, 1409, 3363, 3046, 3356, 4955, 352],\n",
              " [2555, 4410, 3487, 4673, 1767, 756],\n",
              " [1971, 2256, 2687, 3343, 3205, 3960, 1193, 330],\n",
              " [2803, 4394, 1391, 4448, 4406],\n",
              " [2350, 1903, 1408, 1348, 4389, 2331, 3455, 1511, 3704],\n",
              " [1629],\n",
              " [677, 720, 3826, 4691, 1875, 2636, 1794, 2542, 579, 4691],\n",
              " [1876, 313, 3340, 1095, 4848, 3251],\n",
              " [2461, 2823, 1012, 595, 1916, 2542, 579, 4691],\n",
              " [3654, 3748, 2165, 655, 1658, 544, 1876, 2681],\n",
              " [3290, 2962, 3334, 1078, 3853, 1876, 4808],\n",
              " [2082, 3894, 4145, 1644, 3455, 1876, 4800, 2314],\n",
              " [4681, 1903, 4838, 1763, 4601, 656, 2740, 2388, 2542, 579, 4691],\n",
              " [3524, 2813, 4692],\n",
              " [1805, 1971, 2705, 669, 2329, 2542, 579, 4691],\n",
              " [1922, 1891, 4710, 1679, 3420, 1018, 3507, 95, 1761, 4973, 1472, 2314],\n",
              " [3629, 1389, 2160, 2354, 4737, 1766, 296, 4970, 2542, 579, 4691],\n",
              " [1408, 242, 3734, 741, 4639, 1564, 4673],\n",
              " [3250, 4657, 4234, 1398, 3540, 19, 2184, 3266, 4564, 556, 3544, 590],\n",
              " [242, 108, 1654, 4549, 686],\n",
              " [1633, 3990, 756, 1876, 2141, 735, 3624, 2762, 2542, 579, 4691],\n",
              " [1815, 2631, 4042, 3847, 939, 4254, 2542, 579, 4691],\n",
              " [3273, 29, 108, 1727, 4315, 1815],\n",
              " [4530, 4573, 3387, 4959, 3336, 3119, 4456, 2542, 579, 4691],\n",
              " [912, 2132, 4959, 1472, 354, 4721, 347, 3635, 347],\n",
              " [4647, 1986, 353, 3240, 2293, 669, 2542, 579, 4691],\n",
              " [134, 4794, 377, 3853, 134, 1713, 2888, 4620],\n",
              " [4267, 2728, 1157, 1291, 2720, 1515, 4980, 4286, 2848, 4254],\n",
              " [1654, 2770, 3767, 630, 1880, 2569, 2314],\n",
              " [3539, 2521, 4981, 2586, 3826, 4758, 3706, 4900, 2542, 579, 4691],\n",
              " [898, 106, 4548, 846, 1727, 1724],\n",
              " [3328, 872, 622, 4660, 1430, 3062, 1488, 747, 4759, 106, 2314],\n",
              " [4808, 1587, 2798, 2332, 1398, 2843, 2598, 644],\n",
              " [550, 2280, 1831, 3748, 3104, 2444, 218],\n",
              " [1876, 3240, 95, 1616, 60, 2413, 1408, 4198, 2749, 2542, 579, 4691],\n",
              " [2833, 2992, 2587, 1876, 3471, 2725, 2280, 218, 2314],\n",
              " [1070, 3459, 1854, 1876],\n",
              " [251, 991, 4588, 4057, 934, 2526, 4854],\n",
              " [421, 629, 1344, 1619, 2432, 4983, 2483, 722, 4340],\n",
              " [3384, 3748, 2266, 2941, 1876, 1444],\n",
              " [1408, 4350, 2924, 1876, 2426, 4688, 1160, 2382, 3175, 559, 2542, 579, 4691],\n",
              " [3544, 3281, 4759, 2092, 1111, 1010, 2956, 1667, 3395, 1185, 2542, 579, 4691],\n",
              " [671, 363, 2503, 4585, 4585, 4585, 2542, 579, 4691],\n",
              " [358, 2019, 4923, 2971, 2092, 2405, 4978, 4247],\n",
              " [242, 491, 370, 2857, 242, 4258, 770, 826, 1761, 268],\n",
              " [1357, 3484, 4751, 296, 1916, 2542, 579, 4691],\n",
              " [1923, 1395, 334, 1778, 3252, 1539, 1587, 3563, 2542, 579, 4691],\n",
              " [1876,\n",
              "  1727,\n",
              "  2031,\n",
              "  1903,\n",
              "  3252,\n",
              "  3241,\n",
              "  1072,\n",
              "  4144,\n",
              "  1707,\n",
              "  3688,\n",
              "  1318,\n",
              "  1689,\n",
              "  2314],\n",
              " [684, 3390, 4869, 1062, 1582, 623, 412, 3885],\n",
              " [3255, 2942, 2522, 3265, 3334, 242, 557, 3455],\n",
              " [3315, 1459, 1610, 106, 2246, 2542, 579, 4691],\n",
              " [2417, 129, 2770, 2571, 4355, 113, 1876, 3618, 2314],\n",
              " [2568, 207, 3894, 3015, 1961, 503, 3256, 1876, 2542, 579, 4691],\n",
              " [1834, 1813, 669, 3355, 4686, 2542, 579, 4691],\n",
              " [2770, 3378, 3024, 686, 4498, 3751, 4135, 4656, 2542, 579, 4691],\n",
              " [893, 578, 3252, 4025, 2486, 4759, 1922, 1062, 3320, 3175, 2371, 1767],\n",
              " [2647, 4283, 3378, 308, 4060, 4669, 1896, 2542, 579, 4691],\n",
              " [3748, 900, 2631, 242, 1931, 1616],\n",
              " [4759, 2366, 637, 4190, 1121, 2183],\n",
              " [3475,\n",
              "  3765,\n",
              "  2542,\n",
              "  579,\n",
              "  4691,\n",
              "  60,\n",
              "  1587,\n",
              "  1391,\n",
              "  1113,\n",
              "  3452,\n",
              "  140,\n",
              "  3328,\n",
              "  2952,\n",
              "  802,\n",
              "  2542,\n",
              "  579,\n",
              "  4691],\n",
              " [505, 2587, 1403, 1078, 3024, 4875, 2924, 1876, 2681, 2314],\n",
              " [252, 4396, 1408, 2475, 3239, 1113, 4761, 1717, 3365, 3748, 2314],\n",
              " [1938, 4771, 2185, 3654, 2542, 579, 4691],\n",
              " [3450, 1433, 3700, 804, 2770, 3256, 629],\n",
              " [1727,\n",
              "  1747,\n",
              "  424,\n",
              "  4657,\n",
              "  2049,\n",
              "  3233,\n",
              "  871,\n",
              "  2003,\n",
              "  2354,\n",
              "  2498,\n",
              "  4075,\n",
              "  875,\n",
              "  4978,\n",
              "  644],\n",
              " [3748, 4358, 455, 1372, 2329, 2706, 2799, 2631, 3340, 2542, 579, 4691],\n",
              " [4067, 2331, 4799, 1709, 1876, 3826, 4721, 3670, 2208, 3424, 2293, 2314],\n",
              " [2111, 4689, 4620, 1815, 2941, 4036, 1486, 2314],\n",
              " [4872, 717, 4829, 3684, 2032, 1086, 656, 3352],\n",
              " [4593, 1458, 2571, 2513, 2022, 1433, 2345],\n",
              " [2364, 1530, 4534, 242, 4258, 4548, 1291, 4548, 3394],\n",
              " [3845, 1010, 316, 117, 2542, 2655, 4689, 2542, 579, 4691],\n",
              " [1391, 370, 1548, 3125, 2447, 303, 3728, 1745, 4396],\n",
              " [4198, 4258, 1472, 2290, 3146, 408, 435, 2314],\n",
              " [3838, 2770, 4888, 2035, 3473, 4345, 3937, 435, 2314],\n",
              " [189, 1521, 2367, 905, 4021, 473, 4760, 752, 2942, 3985],\n",
              " [3024, 4389, 181, 1923, 1719, 3148, 3985, 1610, 2469, 431, 3556, 84],\n",
              " [1408, 4364, 3988, 2369, 595, 1876, 2542, 579, 4691],\n",
              " [223, 1298, 4241, 908, 4793, 4125, 3501, 2542, 579, 4691],\n",
              " [506, 595, 4741, 3352, 229, 1195, 2833, 3610, 1574],\n",
              " [934, 1392, 3685, 1660, 1604],\n",
              " [3871, 1876, 2194, 492, 117, 1409, 408, 2314],\n",
              " [2469, 1825, 4691, 1616, 2542, 579, 4691],\n",
              " [1806, 1113, 4833, 3410, 4759, 246, 1782, 4055, 1612, 2498, 190],\n",
              " [3228, 705, 3547, 1836, 3580, 4573, 3387, 2542, 579, 4691],\n",
              " [416, 651, 2259, 4737, 2329, 1930, 4777, 2314],\n",
              " [1160, 1415, 1288, 3081, 4657, 1876, 2180, 2314],\n",
              " [1876, 532, 1244, 1619],\n",
              " [3387, 2280, 3500, 4072, 4568, 2542, 579, 4691],\n",
              " [1408, 2525, 3455, 2893, 2410, 4520, 3340, 3359, 1275, 2542, 579, 4691],\n",
              " [2542, 4977, 2132, 1724, 2468, 1, 2599, 2252, 4137, 2802, 2542, 579, 4691],\n",
              " [62, 4709, 4689, 3544, 3038, 4657, 2803, 411, 2314],\n",
              " [2965, 4900, 2224, 856, 1781, 3967],\n",
              " [2942, 3487, 2542, 579, 4691],\n",
              " [2889, 4112, 1408, 3976, 4942, 2070, 2870, 4166],\n",
              " [1668, 3554, 2942, 4142, 1959, 1809, 1868, 2173, 3643, 2314],\n",
              " [4963, 1709, 3721, 4777, 2542, 579, 4691],\n",
              " [3618, 2331, 3607, 1876, 1010, 106, 2498, 424, 314, 3062, 144, 170, 2314],\n",
              " [1473, 802, 4872, 2426, 802, 4162, 1991, 802],\n",
              " [4955, 2879, 3410, 1096, 2799, 3249, 4578, 2542, 579, 4691],\n",
              " [2965, 727, 1892, 3711, 3500, 2610],\n",
              " [2129, 4364, 140, 3956, 3767, 4145, 3278, 2064, 1148],\n",
              " [4541, 1540, 1391, 4448, 4406],\n",
              " [1876, 2681, 2787, 1616, 809, 2057, 3119, 2314],\n",
              " [1876, 3738, 2031, 1343, 332, 4657, 3417, 2377, 2542, 579, 4691],\n",
              " [9, 880, 4021, 473, 4067, 4328, 1113, 2314],\n",
              " [4383, 65, 3967, 3880, 2162, 3289, 3001],\n",
              " [1408, 242, 3024, 2475, 1974, 2533, 4663, 1727],\n",
              " [173, 3471],\n",
              " [696, 3403, 4078, 2794, 1178, 4820, 3064],\n",
              " [935, 4520, 2941, 1571, 2688, 3960, 106, 2542, 579, 4691],\n",
              " [1407, 666, 3706, 2229, 623, 3356, 3885, 2542, 579, 4691],\n",
              " [4899, 3020, 4475, 1876, 1783, 4975, 874, 3605, 3113, 3635, 235],\n",
              " [1348, 1005, 1708, 3821, 1815, 922, 879, 1708, 3113, 2366],\n",
              " [2462, 2493, 4052, 1790, 2069, 268, 1295, 2542, 579, 4691],\n",
              " [134, 2550, 855, 4534, 1592, 1727, 2426, 2621, 4870, 2644, 4588, 3047],\n",
              " [503],\n",
              " [1096, 2498, 2962, 4534, 1072, 2435, 4673, 2803, 1689, 2314],\n",
              " [1686,\n",
              "  3438,\n",
              "  4286,\n",
              "  1166,\n",
              "  2191,\n",
              "  4232,\n",
              "  2669,\n",
              "  4588,\n",
              "  3960,\n",
              "  3228,\n",
              "  4998,\n",
              "  2542,\n",
              "  3540,\n",
              "  1501],\n",
              " [1096, 2498, 4283, 1941, 1216, 3358, 1566, 4673, 4833, 4475],\n",
              " [330, 4908, 2658, 117, 535, 820, 436, 2846, 1619],\n",
              " [2914, 1029, 4657, 3894, 3465, 4643],\n",
              " [2542, 410, 471, 2759, 3826, 4414, 3776, 4926],\n",
              " [1285, 381, 2744, 2476, 4789, 2996, 2571, 1510, 165, 2314],\n",
              " [1899, 4848, 3805, 2146],\n",
              " [4534, 3830, 2774, 2984, 2436, 1781, 3070, 2542, 579, 4691],\n",
              " [4476, 4869, 1525, 2115, 2666, 4992, 3945, 2542, 579, 4691],\n",
              " [1169, 2793, 3723, 1228, 418, 9],\n",
              " [4777, 2542, 579, 4691],\n",
              " [2631, 2571, 503, 2883, 2870, 2180],\n",
              " [1922, 1891, 1897, 3224, 3702, 3751, 1464, 975, 3845, 2259, 4201],\n",
              " [2693, 1586, 2388, 1318, 3252, 2980, 2239],\n",
              " [1165, 4276, 4632, 4406, 4010, 2542, 579, 4691],\n",
              " [242, 3024, 1289, 3584, 3390, 1362, 2906, 4549, 4361, 3767],\n",
              " [1960, 4410, 14, 1414, 2000, 756, 16, 2542, 579, 4691],\n",
              " [1799, 2049, 2713, 2882, 1771],\n",
              " [2941, 3745, 4112, 4588, 2032, 3834, 4057],\n",
              " [4656, 1798, 4820, 2532, 2008, 3075, 2326, 1527, 1471, 4458, 2542, 579, 4691],\n",
              " [4588, 4226, 2481, 3107, 4673, 2615, 879, 1609],\n",
              " [4859, 363, 2922, 2864, 107, 4846, 4777, 2451, 2542, 579, 4691],\n",
              " [611, 4568, 2736, 1458, 2548, 19, 3487, 4568, 3148, 2314],\n",
              " [3303, 453, 684, 2209, 3044, 3251, 2168, 1702, 620, 1025, 1590, 1692, 2801],\n",
              " [3788, 3668, 598, 1408, 1876, 3734, 1460, 759, 2759],\n",
              " [1344, 159, 1097, 1827, 2049, 4191, 899, 106, 2542, 579, 4691],\n",
              " [1727, 3965, 4015, 3175, 1115, 4336, 4663, 4254],\n",
              " [2034, 1311, 1194, 1291, 3252, 4035, 2314],\n",
              " [382, 4959, 3252, 2542, 579, 4691],\n",
              " [539, 3702, 2811, 4247, 2115, 4629, 4882, 4938, 2314],\n",
              " [4732, 4102, 4437, 2542, 579, 4691],\n",
              " [4588, 3116, 4689, 3745, 2550, 2013, 4057, 2913, 2049, 1587, 229, 3250, 2206],\n",
              " [2542, 3024, 686, 2962, 4080, 2498, 2611, 2906, 4549],\n",
              " [1638, 4260, 4689, 1831, 2504, 2620, 3826, 1727, 2542, 579, 4691],\n",
              " [2696, 4254, 2542, 579, 4691],\n",
              " [1835, 4414, 617, 1767, 2542, 579, 4691],\n",
              " [3739, 1408, 20, 4659, 268, 2725, 2314],\n",
              " [2034, 3334, 986, 424, 436, 2542, 4215, 3340, 2542, 579, 4691],\n",
              " [353, 1486, 1767, 4632, 4777, 2542, 579, 4691],\n",
              " [4319, 1944, 3584, 4387, 412, 659, 1835, 2542, 579, 4691],\n",
              " [4022, 2137, 1876, 2604, 3856, 4243, 2542, 579, 4691],\n",
              " [3932,\n",
              "  3266,\n",
              "  1612,\n",
              "  2635,\n",
              "  4580,\n",
              "  4307,\n",
              "  2631,\n",
              "  412,\n",
              "  1912,\n",
              "  1588,\n",
              "  4051,\n",
              "  1137,\n",
              "  569,\n",
              "  3206,\n",
              "  1558],\n",
              " [1815, 3390, 888, 2334, 2728, 3751, 3670, 2314],\n",
              " [4555, 2309, 1876, 569, 1404, 3637, 3057, 2542, 579, 4691],\n",
              " [1761, 1342, 3390, 4869, 720, 2436, 1447, 1409],\n",
              " [1610, 2469, 1777, 1719, 686, 3438, 3540, 81, 915],\n",
              " [2924, 1876, 4662, 2450, 1157, 1673, 1854, 2487, 2618, 2542, 579, 4691],\n",
              " [4303, 1836, 1515, 1617, 3259, 4588, 1148, 2160, 2034, 3861],\n",
              " [2329, 2846, 2565, 4049, 4060, 2387, 2208],\n",
              " [2631, 1059, 747, 1049, 1648, 1574, 2952, 4908, 172, 669, 2039, 2314],\n",
              " [2919, 303, 3728, 1036, 3806, 985, 3041, 4406],\n",
              " [1511, 2426, 2621, 2400, 4792, 3047, 4248, 2618, 3565, 4161],\n",
              " [242, 3814, 2924, 1876, 2941, 3665, 3767],\n",
              " [1815, 1876, 4259, 1680, 2345, 630, 4435, 4834, 1876, 2314],\n",
              " [3933, 2413, 4132, 431, 97, 3197, 2354, 4540, 1901, 3394, 2542, 579, 4691],\n",
              " [1876, 3292, 3865, 595, 1344, 232, 4403, 3787, 2160, 2542, 579, 4691],\n",
              " [2924, 1876, 2124, 4198, 701, 1185, 4820, 2657, 4132, 1314],\n",
              " [4604, 2552, 1061, 3716, 4415, 2047],\n",
              " [4057, 3252, 4794, 1716, 1394, 2947, 2450, 770, 931],\n",
              " [3417, 1129, 2553, 4620, 61, 1244],\n",
              " [4673, 4959, 2857, 4475, 2035, 3373, 2542, 579, 4691],\n",
              " [1582, 4112, 2168, 815, 2092, 55, 1010, 568, 4799, 473],\n",
              " [611, 2483, 3912, 1408, 3929, 4673, 1591, 1609, 4620],\n",
              " [1971, 4244, 3295, 2020, 3937, 2820, 2542, 579, 4691],\n",
              " [1494, 388, 1318, 2526, 3843, 4600, 67, 2873, 4448],\n",
              " [4,\n",
              "  4587,\n",
              "  2004,\n",
              "  3146,\n",
              "  2679,\n",
              "  4008,\n",
              "  1421,\n",
              "  3563,\n",
              "  242,\n",
              "  3024,\n",
              "  1771,\n",
              "  706,\n",
              "  3723,\n",
              "  4132],\n",
              " [1974, 2593, 3767, 4112, 4369, 1815, 1291, 908, 2542, 579, 4691],\n",
              " [3876, 4112, 61, 4331, 3024, 2516],\n",
              " [1876, 3292, 4248, 655, 3328, 3799, 313, 2542, 579, 4691],\n",
              " [3075, 4700],\n",
              " [1876, 706, 437, 4125, 4332, 4759, 4419, 4578, 1034, 1010, 770, 2468, 4808],\n",
              " [1980, 2092, 2631, 2329, 556],\n",
              " [2208, 1840, 1827, 1228, 4808],\n",
              " [2168, 4632, 35, 4673, 1523, 2498, 4504, 129],\n",
              " [3932,\n",
              "  4389,\n",
              "  2828,\n",
              "  2483,\n",
              "  2526,\n",
              "  3748,\n",
              "  1062,\n",
              "  2533,\n",
              "  3962,\n",
              "  4389,\n",
              "  2828,\n",
              "  2483,\n",
              "  2526,\n",
              "  3748,\n",
              "  1062,\n",
              "  2533,\n",
              "  3962,\n",
              "  2542,\n",
              "  4072,\n",
              "  9],\n",
              " [1717, 2049, 2043, 1006, 1619, 1989],\n",
              " [3022, 358, 623, 2154, 2645, 3985, 4817, 3584, 553],\n",
              " [1096, 2914, 4369, 2184, 4629, 556, 4345, 2109, 4254, 1587, 756, 1931, 3723],\n",
              " [862, 884, 2924, 1876, 4441, 1431, 3670, 892, 2542, 579, 4691],\n",
              " [4067, 2253, 2979, 4012, 3340, 4474, 262, 2037, 3040, 595, 1080, 2314],\n",
              " [3666, 3390, 4802, 770, 669],\n",
              " [4153,\n",
              "  751,\n",
              "  1408,\n",
              "  2019,\n",
              "  3670,\n",
              "  1408,\n",
              "  3544,\n",
              "  3403,\n",
              "  4029,\n",
              "  637,\n",
              "  2100,\n",
              "  2118,\n",
              "  4770,\n",
              "  908,\n",
              "  4919,\n",
              "  4808],\n",
              " [4024, 4534, 197, 559, 1511],\n",
              " [2599, 3119, 1706, 3024, 2947, 2618, 2354],\n",
              " [1876, 3273, 4976, 3605, 2542, 3540, 1501],\n",
              " [1608, 567, 1713, 2388, 3024, 1876, 4688, 4263, 2542, 579, 4691],\n",
              " [2647, 190, 2280, 2359, 181, 570, 2971, 2542, 579, 4691],\n",
              " [3826, 79, 2844, 1011, 2672, 3748, 4661, 2498, 2104, 2762],\n",
              " [3584, 419, 4405, 2813, 4942, 2070, 2870, 2180],\n",
              " [3956, 708, 4161, 3350, 153, 568, 440, 1344, 4942],\n",
              " [3499, 4806, 1000, 1614, 257, 2180, 4160, 2571, 1184, 3186, 2314],\n",
              " [3313, 756, 4230, 2326, 4814, 2669],\n",
              " [242, 2364, 4022, 1770, 2925, 3251, 4075],\n",
              " [4956, 1080, 4453, 144, 1372, 2694, 1750, 3907],\n",
              " [3403, 1876, 2540, 1014, 4399, 2542, 579, 4691],\n",
              " [3898,\n",
              "  3487,\n",
              "  1752,\n",
              "  4479,\n",
              "  1708,\n",
              "  3175,\n",
              "  4465,\n",
              "  1473,\n",
              "  4531,\n",
              "  3243,\n",
              "  3819,\n",
              "  1391,\n",
              "  1805],\n",
              " [2093, 2583, 2020, 1876, 1343, 2348, 2655, 4680],\n",
              " [3745, 19, 1876, 3041, 113, 2142, 4444, 396, 3449],\n",
              " [4934, 277, 4313, 2390, 15, 1609, 455, 3246, 4870, 2542, 579, 4691],\n",
              " [2373, 2689, 4144, 595, 4335, 1145, 2599, 2987, 4549, 2542, 579, 4691],\n",
              " [1434, 3390, 4869, 4266, 4893, 2019, 3328, 2082, 2334, 4973, 802],\n",
              " [1903,\n",
              "  2032,\n",
              "  4396,\n",
              "  443,\n",
              "  3251,\n",
              "  4158,\n",
              "  3397,\n",
              "  2803,\n",
              "  1437,\n",
              "  4947,\n",
              "  1876,\n",
              "  3397,\n",
              "  1193,\n",
              "  2314],\n",
              " [3401, 716, 556, 2019, 3540, 2540],\n",
              " [2621, 2542, 579, 2631, 4248, 4447, 2655, 4689, 2542, 579, 4691],\n",
              " [1876, 2184, 1782, 1192, 2804, 697, 2542, 4808, 2103, 2631, 1937],\n",
              " [1157, 2004, 3069, 1291, 3273, 2346, 3562, 1536, 2542, 579, 4691],\n",
              " [4932, 1876, 2150, 3745, 3340, 4254, 3826, 4372, 11, 2314],\n",
              " [2409, 3745, 3334, 2483, 2367, 2820, 308, 2913, 4946, 2409, 3745],\n",
              " [2082, 4432, 9, 4176, 4248, 3233, 4399, 2314],\n",
              " [4254, 1460, 2925, 3397],\n",
              " [4910,\n",
              "  1708,\n",
              "  2250,\n",
              "  277,\n",
              "  1494,\n",
              "  2405,\n",
              "  360,\n",
              "  200,\n",
              "  4657,\n",
              "  3302,\n",
              "  770,\n",
              "  2922,\n",
              "  2941,\n",
              "  3340,\n",
              "  2314],\n",
              " [2564, 3043, 1520, 4808, 1509, 2567, 4099, 2542, 579, 4691],\n",
              " [3515, 2142, 1587, 3606, 3395, 2259, 550, 2269, 270],\n",
              " [1719, 2065, 2873, 2492, 686],\n",
              " [3805, 335, 3255, 373, 4405, 4406],\n",
              " [4022, 1407, 3807, 4022, 3456, 1535, 242, 2978, 1876, 3807, 60],\n",
              " [1062, 4307, 1360, 458, 2688, 2655, 562, 3355, 4794, 4808],\n",
              " [242, 3024, 3544, 2272, 2046, 3477, 2272, 1639, 370, 2542, 579, 4691],\n",
              " [4588, 1239, 3246, 1539, 4765, 3845, 106, 3453],\n",
              " [985, 1619, 4533, 4820, 2075, 2599, 4399, 3723, 3670, 1635],\n",
              " [4534, 4234, 3334, 525, 2708, 4145, 946, 1727, 1221, 4776, 4540, 2314],\n",
              " [3239, 1113, 2252, 2390, 2280, 2184, 2542, 579, 4691],\n",
              " [4548, 1876, 3748, 4045, 644, 3271],\n",
              " [1472, 3024, 3875, 117, 4955, 242, 3776],\n",
              " [4057,\n",
              "  4221,\n",
              "  4187,\n",
              "  927,\n",
              "  2789,\n",
              "  632,\n",
              "  884,\n",
              "  1225,\n",
              "  1642,\n",
              "  4371,\n",
              "  3344,\n",
              "  4838,\n",
              "  4306,\n",
              "  1802,\n",
              "  2049],\n",
              " [1995, 550, 1722, 720, 2182, 809, 3600, 2542, 579, 4691],\n",
              " [1815, 1876, 3410, 3360, 3851, 4814, 2873, 1228, 2314],\n",
              " [1472, 3024, 3167, 4021, 3228, 2307, 2280, 475, 1076, 1408, 3390],\n",
              " [2940, 3427, 1936, 556, 3889, 3540, 2770, 986, 1368],\n",
              " [1272, 1876, 2046, 3670],\n",
              " [4910, 15, 1275, 4620, 3465, 1836, 3894, 451, 2542, 579, 4691],\n",
              " [1288, 1133, 746, 3928, 1021, 3515, 2693, 3810, 2542, 579, 4691],\n",
              " [1244, 3076, 2943, 1645, 2147, 1163, 2314],\n",
              " [1836, 3277, 2708, 3417, 1937, 4145, 559, 416, 2542, 579, 4691],\n",
              " [4722, 2954, 1876, 2184, 691, 1614, 452, 332, 1566],\n",
              " [4657, 3605, 1876, 1129, 1706, 2480, 1166, 4534, 4234, 3747],\n",
              " [1799, 210, 2268, 4153],\n",
              " [1876, 8, 522, 1537, 4328, 9, 3251, 246, 2314],\n",
              " [1157, 2004, 1547, 898, 2943, 3851, 118, 79, 2542, 579, 4691],\n",
              " [4179, 2043, 1205, 1913, 4834, 3716, 1810, 2542, 579, 4691],\n",
              " [546, 751, 2019, 892, 2356, 3933, 2542, 579, 4691],\n",
              " [4959, 2150, 155, 4793, 802, 1580, 2503, 3252, 4110, 2542, 579, 4691],\n",
              " [3748, 2820, 4548, 2268, 1409, 2879, 4258, 192, 2542, 579, 4691],\n",
              " [3830, 8, 3780, 4863, 3271, 4057, 4692, 1310, 2542, 579, 4691],\n",
              " [1835, 2068, 1006, 3054, 3020, 1179, 3751, 2280, 3873],\n",
              " [2924, 1876, 1408, 104, 2600, 3387, 2542, 579, 4691],\n",
              " [],\n",
              " [144, 2374, 4132, 1037, 2280, 218, 662, 550, 2019],\n",
              " [2225, 420, 1401, 975, 2965, 3277, 1777, 4594, 61],\n",
              " [4817, 419, 1590, 2873, 2542, 3390],\n",
              " [3932, 2631, 716, 1805, 2993, 242, 2366, 4643, 1456],\n",
              " [3956, 708, 2827, 3385, 1503, 4534, 4234, 242, 3024],\n",
              " [1876, 599, 1959, 752, 2618, 2542, 579, 4691],\n",
              " [3970, 4817, 4212, 4869, 436, 1876, 3723, 2873, 1995, 2498],\n",
              " [458, 3738, 3328, 4145, 4198, 1588, 3003, 2542, 579, 4691],\n",
              " [4950, 1473, 1129, 4585, 4153, 3563, 2314],\n",
              " [3251, 424, 1195, 3397, 1291],\n",
              " [3914, 3780, 2759, 3926, 1471, 3914, 1836, 3851, 449, 2062, 2550, 1713, 2493],\n",
              " [4681, 2993, 4915, 2542, 579, 4691],\n",
              " [4585, 2526, 1914, 2332, 2542, 579, 4691],\n",
              " [2794,\n",
              "  3434,\n",
              "  681,\n",
              "  4820,\n",
              "  3563,\n",
              "  1473,\n",
              "  4808,\n",
              "  4220,\n",
              "  2482,\n",
              "  596,\n",
              "  4833,\n",
              "  3302,\n",
              "  1614,\n",
              "  4820,\n",
              "  1608,\n",
              "  1931,\n",
              "  2657,\n",
              "  2635],\n",
              " [3618, 60, 2214, 3521, 3119, 2092, 3463, 3547, 123, 2508, 2314],\n",
              " [605, 767, 534, 4680, 2799, 4914, 2975, 3762, 2314],\n",
              " [2388, 4057, 3621, 4513, 4756, 440, 2258, 2454, 3484, 3266, 4564],\n",
              " [4909, 3970, 1785, 1938, 313, 2427, 1221, 3473, 4918, 1061, 4587, 1894, 2314],\n",
              " [1972, 2993, 4247, 3467, 3146, 3434, 3765, 2150, 1039],\n",
              " [467, 1892, 4187, 3663, 2693, 2061, 3252, 595, 2587, 625, 218, 2314],\n",
              " [3328, 1457, 4843, 2913, 3487, 356],\n",
              " [2005, 4186, 3037, 2981, 2208, 1345, 4385, 557, 3473, 2314],\n",
              " [3243, 3633, 218, 1845, 4031, 2618, 1421, 3662],\n",
              " [2917, 44, 2913, 4580, 2542, 579, 4691],\n",
              " [1818, 2924, 1876, 222, 377, 656, 3387, 2542, 579, 4691],\n",
              " [4178, 242],\n",
              " [1640, 4793, 2184, 1000, 939, 2542, 579, 4691],\n",
              " [3932, 1761, 3269, 888, 1744, 4817, 1761, 4132, 2912],\n",
              " [695, 3024, 568, 2762],\n",
              " [1157, 2820, 525, 3273, 3334, 1876, 2542, 579, 4691],\n",
              " [3240, 4187, 1106, 3390, 4869, 373, 2293, 2542, 579, 4691],\n",
              " [1761, 1342, 242, 3024, 4102, 1437, 2062, 2542, 579, 4691],\n",
              " [4241, 2369, 4511, 3234, 2813, 4613, 4858],\n",
              " [1876, 3424, 1679, 3380, 2209],\n",
              " [242, 3713, 2506, 190, 2067, 4580, 1473, 843, 793],\n",
              " [3041, 1034, 2813, 1783, 4513, 2542, 579, 4691],\n",
              " [340, 4137, 1893, 3213, 3455, 2542, 579, 4691],\n",
              " [1876, 3985, 4737, 3069, 3464, 4848, 2542, 579, 4691],\n",
              " [2647, 1064, 4739, 4160, 242, 4900, 3998, 546, 2542, 579, 4691],\n",
              " [4180, 2871, 1344, 232, 2019, 3751, 455, 4286, 3826, 2542, 579, 4691],\n",
              " [2100, 1876, 4877, 855, 4435, 396, 1298, 2314],\n",
              " [2466, 1654, 3024, 686, 2943, 4042, 4201, 620, 742, 1876, 2490],\n",
              " [4458, 2307, 2602, 3547, 2115],\n",
              " [3228, 3555, 671, 471, 2068, 2035, 471, 354, 4787, 2314],\n",
              " [1283, 2618, 2101, 2962, 1805, 3723, 2499, 1586, 2497],\n",
              " [1309, 3246, 4419, 277, 4671, 4673, 4473, 2688],\n",
              " [4070, 559, 2354, 3662, 4122, 3350, 374, 2542, 579, 4691],\n",
              " [2129, 4057, 1384, 4132, 3252, 2045, 3723],\n",
              " [1876, 3695, 3991, 268, 1815, 3390, 1362, 2035, 4331],\n",
              " [1636, 1876, 4689, 4760, 2602, 4580, 2293, 2314],\n",
              " [422, 3670, 1815, 4562, 3468, 4833, 4475, 4254, 1291, 2924, 1876],\n",
              " [3563, 1121, 3723],\n",
              " [],\n",
              " [3584, 419, 4405, 2813, 4548, 4942, 2070, 2870, 2180],\n",
              " [3373, 1309, 1703, 2116, 3054, 4978, 2082, 2962],\n",
              " [837, 2416, 2221, 4423, 1345, 4758, 3970, 106, 4355],\n",
              " [2759, 4145, 242, 3024, 3751],\n",
              " [3401, 4802, 1669, 722, 4158, 624, 106],\n",
              " [3723, 2820, 3756, 2542, 141],\n",
              " [242, 3767, 598, 1408, 4125],\n",
              " [4303,\n",
              "  4325,\n",
              "  2857,\n",
              "  355,\n",
              "  4256,\n",
              "  2108,\n",
              "  1805,\n",
              "  1836,\n",
              "  2498,\n",
              "  210,\n",
              "  165,\n",
              "  2542,\n",
              "  579,\n",
              "  4691],\n",
              " [3932,\n",
              "  1444,\n",
              "  1321,\n",
              "  3362,\n",
              "  4171,\n",
              "  800,\n",
              "  1444,\n",
              "  1321,\n",
              "  3362,\n",
              "  4171,\n",
              "  800,\n",
              "  670,\n",
              "  3463,\n",
              "  1932],\n",
              " [2924, 1876, 4620, 2371, 4370, 656, 3387, 2542, 579, 4691],\n",
              " [4597, 1667, 598, 1408, 4465, 242, 3853, 242, 2568],\n",
              " [8,\n",
              "  3256,\n",
              "  117,\n",
              "  251,\n",
              "  814,\n",
              "  570,\n",
              "  200,\n",
              "  4868,\n",
              "  1185,\n",
              "  4664,\n",
              "  117,\n",
              "  4198,\n",
              "  4258,\n",
              "  4022,\n",
              "  2314],\n",
              " [3818,\n",
              "  3606,\n",
              "  2962,\n",
              "  4247,\n",
              "  1345,\n",
              "  1066,\n",
              "  4054,\n",
              "  739,\n",
              "  4908,\n",
              "  1219,\n",
              "  4534,\n",
              "  2015,\n",
              "  2960,\n",
              "  2314],\n",
              " [4672, 354, 2427, 1783, 1278],\n",
              " [364, 949, 3266, 365, 989, 4060, 2542, 579, 4691],\n",
              " [1291, 2762, 360, 4877, 1574, 3723],\n",
              " [463, 373, 2280, 814, 4024, 2542, 2149, 3175, 813, 2941, 836, 4768],\n",
              " [1876, 3745, 3853, 3845],\n",
              " [770, 3119, 4659, 3465, 1085, 4396, 1587, 3263, 3206],\n",
              " [1587, 1011, 3047, 3887, 1836, 3879, 863, 2542, 579, 4691],\n",
              " [3767, 2345, 727, 4248, 1727, 3960, 1934, 4808],\n",
              " [1169, 2618, 1169, 4241, 2426, 3114],\n",
              " [3539, 2836, 1903, 1597, 1113, 2913, 2049, 730, 4777, 1844, 2542, 579, 4691],\n",
              " [1093, 477, 2631, 2329, 4955, 3748, 1727, 4669, 3131, 2542, 579, 4691],\n",
              " [314, 2269, 3477, 4254, 4843, 3894, 652, 3563],\n",
              " [3592, 1158, 2631, 1354, 4972, 248, 3419, 2115, 2542, 579, 4691],\n",
              " [4688, 4345, 3210, 3266, 4564],\n",
              " [2113, 1042, 4869, 641, 3403, 594, 1931, 3564, 3390, 1913, 2542, 579, 4691],\n",
              " [4436, 1783, 1974, 1999, 4021, 4022, 3340, 846, 3213],\n",
              " [3251, 424, 4568, 3396, 2956, 1995, 1876],\n",
              " [4511, 814, 610, 2924, 1876, 4144, 4613, 3131],\n",
              " [2314, 1113, 1391, 2140, 206, 2314],\n",
              " [1876, 9, 3186, 2288],\n",
              " [1096, 4727, 394, 3340, 1812, 1983, 4740, 1674, 4808, 2314],\n",
              " [856, 2000, 4144, 3255, 373, 1876, 1876, 2542, 579, 4691],\n",
              " [1810, 2131, 3054, 644, 3980, 218, 2844, 1034, 2542, 579, 4691],\n",
              " [629, 1370, 4777, 1694, 3848, 3047, 841, 2542, 579, 4691],\n",
              " [324, 123, 1343, 539, 9, 3273, 1876, 2314],\n",
              " [624, 2889, 475, 2258, 2897, 1011, 2889, 3606, 1291],\n",
              " [3363, 3255, 4332, 1244, 3894, 1247],\n",
              " [669, 684, 1120, 2542, 4631, 1767, 3670],\n",
              " [1544, 3333, 3340, 1874, 4632, 4474],\n",
              " [2647, 1984, 3134, 1644, 4369, 2794, 2258, 3334, 1876, 2542, 579, 4691],\n",
              " [722, 4435],\n",
              " [3894, 481, 948],\n",
              " [1876, 4959, 2979, 856, 3453],\n",
              " [106, 3305, 1718, 3138, 809, 992, 2115, 1354, 2542, 579, 4691],\n",
              " [153, 2599, 3273, 2542, 579, 4900, 735, 2542, 579, 4691],\n",
              " [242, 4299, 118, 727, 4520, 2568, 2314],\n",
              " [1061, 242, 2334, 3024, 539, 1897, 1304, 2504, 2542, 579, 4691],\n",
              " [914, 4720, 60, 4458, 3487, 2942, 2542, 579, 4691],\n",
              " [2019, 1619, 4513, 2542, 579, 4691],\n",
              " [4331, 2896, 4350, 242, 733, 1372, 1597, 19],\n",
              " [1472, 619, 296, 1876, 2618, 4286, 2150, 2542, 2868, 2542, 579, 4691],\n",
              " [884, 95, 3240, 3035, 2924, 1876, 4152, 2542, 579, 4691],\n",
              " [2283,\n",
              "  408,\n",
              "  3301,\n",
              "  1876,\n",
              "  2941,\n",
              "  2542,\n",
              "  2913,\n",
              "  4877,\n",
              "  3266,\n",
              "  4959,\n",
              "  3424,\n",
              "  722,\n",
              "  2019,\n",
              "  4602],\n",
              " [2805, 4153, 3670, 733, 2366, 685, 3251, 4158, 1914, 4632, 2314],\n",
              " [2924, 1876, 3236, 2525, 4806, 1835, 4160, 898, 3610, 3499, 1000],\n",
              " [],\n",
              " [1472, 3431, 2259, 2049, 2913, 4363, 3306, 4777, 3511, 2542, 579, 4691],\n",
              " [1308, 1049, 222, 4620, 218, 4843, 4569, 756, 2542, 579, 4691],\n",
              " [3547, 1148, 1472, 1001, 3302, 4657, 2914, 1510],\n",
              " [3412, 2355, 4124, 559, 34, 4777, 1502, 2542, 579, 4691],\n",
              " [2590, 2669, 927, 1473, 3564, 347, 1825, 3252, 774, 2314],\n",
              " [887, 4275, 693, 4129, 4260, 2257, 3037, 4592],\n",
              " [3618, 1419, 2154, 3228, 2413, 4340, 2184, 4170, 2354, 2413, 2314],\n",
              " [3751, 3776, 1442, 1731, 3350],\n",
              " [4419, 1080, 1012, 1783, 242, 2915, 2542, 579, 4691],\n",
              " [1347, 4970, 1696, 3196, 4788, 1854, 3024, 2542, 579, 4691],\n",
              " [1876, 1854, 1129, 4657, 1876, 4469, 1370, 2468, 4592],\n",
              " [2857, 4408, 2604, 1085, 2115, 95],\n",
              " [1876, 134, 2941, 2612, 1460, 4258, 2314],\n",
              " [2503, 2237, 1716, 3598, 4217, 4832, 3487, 3328, 1648, 1692, 229, 2894],\n",
              " [3745, 313, 2759, 2628, 1876, 532, 1006, 4125, 1894, 3767],\n",
              " [1454, 1900, 2206, 1778, 3250, 1752, 2542, 579, 4691],\n",
              " [1654, 3024, 686, 2943, 4042, 4201, 620, 742, 1876, 2490],\n",
              " [242, 1292, 1761, 2993, 4651, 3835, 3734],\n",
              " [1679, 3044, 1342, 4951, 3340, 4256, 2542, 579, 4691],\n",
              " [87, 1252, 4794, 1679, 118, 3985, 2693, 772, 3723, 271, 242, 1931],\n",
              " [1472, 3024, 3734, 117, 3213, 880, 3310, 242, 3723],\n",
              " [2107, 218, 566, 3572, 1456, 2709, 370, 2542, 579, 4691],\n",
              " [1876, 3648, 4692, 4057, 2657, 3417, 2542, 579, 4691],\n",
              " [1093, 493, 2366, 4673, 399, 13, 3302, 3144, 708, 2542, 579, 4691],\n",
              " [3953, 3829, 1938, 4930, 3350, 559],\n",
              " [2049, 330, 4843, 841, 4075, 3273, 4585, 4161, 4623, 106],\n",
              " [1809, 2540, 4191, 132, 2413, 4657, 1876, 2150],\n",
              " [624, 1159, 4657, 3263, 471],\n",
              " [2092,\n",
              "  2631,\n",
              "  4087,\n",
              "  4101,\n",
              "  4093,\n",
              "  4900,\n",
              "  4405,\n",
              "  1835,\n",
              "  4125,\n",
              "  2354,\n",
              "  2812,\n",
              "  4703,\n",
              "  2314],\n",
              " [2035, 989, 2803, 1690, 3622, 3976, 3904],\n",
              " [4610, 3625, 1037, 1807, 1277, 544, 242, 1931],\n",
              " [4067,\n",
              "  1836,\n",
              "  1679,\n",
              "  3420,\n",
              "  95,\n",
              "  1761,\n",
              "  4973,\n",
              "  4419,\n",
              "  160,\n",
              "  503,\n",
              "  4035,\n",
              "  4206,\n",
              "  905,\n",
              "  1548,\n",
              "  1148,\n",
              "  4585,\n",
              "  2314],\n",
              " [3526, 1790, 4466, 4632, 3058, 598, 1408],\n",
              " [2841, 2873, 2736, 2955, 106, 426, 377, 802, 2542, 579, 4691],\n",
              " [4808, 502, 3853, 1876, 2184, 1782, 4580, 1806, 1113, 2373, 1913],\n",
              " [2621, 3734, 856, 3910, 1770],\n",
              " [684, 2696, 4198, 2763, 1047],\n",
              " [1148, 610, 3301, 3945, 4187, 95, 404, 2542, 579, 4691],\n",
              " [2981, 1703, 1687, 4972, 1651, 271, 2542, 579, 4144, 2542, 579, 4691],\n",
              " [3076, 905, 2316, 106, 4538, 2686, 4057, 4656, 2542, 579, 4691],\n",
              " [1980, 314, 3328, 4479, 2329, 2373, 2600, 2542, 579, 4691],\n",
              " [4198, 1588, 1129, 3643, 260, 95, 349, 2314],\n",
              " [2035, 3544, 279, 2208, 2429, 286, 3968, 3668],\n",
              " [1360, 2049, 1903, 2803, 23, 4132, 406, 569, 925, 1052, 706, 3747, 172, 3465],\n",
              " [1105, 26, 4580, 242, 3024, 4580, 4003, 2730, 136],\n",
              " [1148, 3570, 3742, 3217, 1408, 2868, 1035, 4724, 1783, 2542, 579, 4691],\n",
              " [4391, 4618, 4200, 524, 4963, 2993, 1776, 2993, 2542, 579, 4691],\n",
              " [3906, 3117, 1408, 1050, 3024, 4137, 3634, 2542, 579, 4691],\n",
              " [2440, 3250, 1342, 1876, 2180, 1177, 2542, 579, 4691],\n",
              " [1369, 3029, 3252, 823, 610, 1108, 4144, 3929, 620, 3062],\n",
              " [1876, 2980, 242, 4638, 4396, 197, 3960, 2542, 579, 4691],\n",
              " [4022, 1182, 2631, 569, 4419, 2503, 4854, 875, 1836, 4075, 964],\n",
              " [3932, 884, 3996, 2907, 2705, 1324, 884, 1068, 541, 18, 158],\n",
              " [2745, 575, 1876, 2107, 471, 1233, 3205, 313, 2542, 579, 4691],\n",
              " [4454, 106, 2280, 843, 3465, 79, 1702, 3238, 2077, 640, 2314],\n",
              " [4414, 1548, 3741, 747, 2542, 579, 4691],\n",
              " [2655, 3632, 3927, 1240, 4580, 915, 644, 79, 2542, 579, 4691],\n",
              " [814, 3340, 4534, 4688, 1536, 4515, 4158],\n",
              " [3252, 193, 4166, 3035, 4534, 1000, 991, 1893, 2542, 579, 4691],\n",
              " [3584, 908, 2759, 3623, 4258, 2310, 2542, 579, 4691],\n",
              " [3224, 1414, 3473, 3378, 4350, 4254, 1291, 2924, 1876],\n",
              " [4389, 2252, 2011, 3990, 1006, 871, 419, 2542, 579, 4691],\n",
              " [4158, 2444, 1782, 1404, 4721, 4410, 3729, 1959],\n",
              " [822, 4673, 811, 1538, 2962, 2922, 2550, 2542, 579, 4691],\n",
              " [3213, 900, 3334, 2542, 579, 4691],\n",
              " [706, 259, 747, 3141, 4947, 720, 1309],\n",
              " [2068, 920, 2744, 3785, 1138, 4605, 1694, 2373],\n",
              " [1370, 2611, 4579, 1974, 458, 4951, 3950, 4410, 163, 4166, 2542, 579, 4691],\n",
              " [3485, 2467, 2006, 747, 1421, 4144, 4720, 2314],\n",
              " [4886, 4088, 1115, 700, 1156, 2250, 4057, 4793, 2138, 4828, 2542, 579, 4691],\n",
              " [1654, 4505, 2542, 2943, 686, 3024, 4898, 3251, 1906],\n",
              " [693, 1868, 4588, 3158, 2015, 1380],\n",
              " [1903, 303, 2118, 1876, 3838, 484, 1473, 4406, 1940],\n",
              " [1062, 814, 1029, 4682, 671, 1536],\n",
              " [4838, 2007, 4051, 1121, 3540, 4588, 4910, 3075],\n",
              " [116, 3996, 2154, 158, 2542, 579, 4691],\n",
              " [2924, 1876, 3554, 4110, 152, 1727, 770, 3648, 2542, 579, 4691],\n",
              " [524, 4145, 1819, 4972, 961, 3440, 2542, 579, 4691],\n",
              " [3547, 283, 4088, 3580, 4573, 3387, 2542, 579, 4691],\n",
              " [2647, 4791, 3038, 1098, 621, 1049, 908, 2542, 579, 4691],\n",
              " [1762, 4350, 3768, 2032, 1010, 1336, 3142, 4329, 3352, 2571, 2542, 579, 4691],\n",
              " [3723, 2959, 2367, 4132, 2045, 3723, 595, 845],\n",
              " [2788, 3716, 357, 1654, 2160, 2770, 2873, 3328, 2542, 3024, 686, 2943],\n",
              " [2924, 1876, 119, 4021, 352, 4137],\n",
              " [229, 1169, 4663, 207, 3069, 4254, 2542, 579, 4691],\n",
              " [605, 4028, 1231, 3748, 4689, 1411, 4673, 3199, 2542, 579, 4691],\n",
              " [4418, 2366, 658, 1228, 3373],\n",
              " [614, 888, 3487, 3328, 4580, 465, 1876, 340, 3438, 2314],\n",
              " [280, 4447],\n",
              " [1995, 4117, 2214, 1692, 2401, 4473, 3252, 1366, 3397],\n",
              " [246, 3640, 242, 3024, 4419, 3102, 3001, 3723, 846],\n",
              " [134, 2669, 3032, 3003, 522, 4373, 3228, 4998, 2542, 579, 4691],\n",
              " [2181, 1395, 2367, 1360, 4848],\n",
              " [884,\n",
              "  1848,\n",
              "  4820,\n",
              "  200,\n",
              "  3569,\n",
              "  4820,\n",
              "  884,\n",
              "  4762,\n",
              "  1456,\n",
              "  1930,\n",
              "  1833,\n",
              "  4820,\n",
              "  884,\n",
              "  4292,\n",
              "  2970,\n",
              "  2794,\n",
              "  1901,\n",
              "  1228,\n",
              "  3918],\n",
              " [595, 3397, 3175, 3796, 3624, 3487, 3273],\n",
              " [4193, 1535, 2210, 1927, 190, 4324],\n",
              " [1876, 3723, 2503, 4160, 4137, 745],\n",
              " [4803, 3929, 2759, 525, 2056, 1157, 4254, 3826, 3800, 1129, 2314],\n",
              " [1511, 3540, 2941, 3723, 1876, 1353, 2141, 251, 435, 1408],\n",
              " [4727, 443, 1876, 2064, 1849, 503, 3234, 4897, 1411, 2618],\n",
              " [3378, 1245, 1141],\n",
              " [661, 1782, 4914, 4389, 1129, 268],\n",
              " [4569, 1831, 3465, 569, 1616, 1464, 2542, 579, 4691],\n",
              " [1529, 655, 1343, 3933, 612, 2057, 3966, 3062, 4612, 2314],\n",
              " [3147, 1271, 4557, 492, 2348, 3259, 2897, 1978, 4190, 1527],\n",
              " [1903, 1668, 106, 735, 1415, 347, 912, 644, 79, 2314],\n",
              " [4112, 1327, 579, 2694, 1745, 2232, 3937],\n",
              " [1080, 4160],\n",
              " [2941, 865, 4256, 2888, 3211, 3093, 2542, 579, 4691],\n",
              " [1668, 4914, 4976, 360, 1607, 2820, 2150, 2314],\n",
              " [4201, 370, 242, 4214, 1084, 1815, 1245],\n",
              " [2259, 2373, 3792, 1044, 871, 340, 2542, 579, 4691],\n",
              " [105, 3721, 3478, 3403, 2497, 2542, 579, 4691],\n",
              " [101, 1120, 2462, 1293, 373, 2542, 579, 4691],\n",
              " [770, 3324, 809, 992, 1635, 2000, 2542, 579, 4691],\n",
              " [1876, 2122, 3292, 2522, 3119, 3256, 832, 2539, 2132, 2542, 579, 4691],\n",
              " [4715,\n",
              "  3852,\n",
              "  2759,\n",
              "  374,\n",
              "  1815,\n",
              "  3742,\n",
              "  3168,\n",
              "  422,\n",
              "  1112,\n",
              "  4102,\n",
              "  60,\n",
              "  948,\n",
              "  2735,\n",
              "  2542,\n",
              "  579,\n",
              "  4691],\n",
              " [2727, 4890, 3980, 1679, 4241, 2542, 579, 4691],\n",
              " [3365, 3508, 4441, 3403, 4689, 1876, 2370],\n",
              " [1903, 1876, 242, 2468, 4592, 1129, 2925, 2866, 1679, 3420, 2314],\n",
              " [2788, 2936, 3076, 158, 360, 2111, 1995, 1985, 3251, 2314],\n",
              " [4657, 4588, 4604, 1461, 2542, 242, 686, 796, 2959, 4393, 3747, 1654],\n",
              " [1012, 313, 4975, 4657, 1983, 3290, 2542, 579, 4691],\n",
              " [376, 4971, 984, 1361],\n",
              " [4021, 1912, 3571, 4548, 4315, 2280],\n",
              " [630, 3547, 4419, 197, 4898, 2799, 3997, 2314],\n",
              " [2647, 4590, 2250, 3356, 2303, 3273, 693, 2542, 579, 4691],\n",
              " [871, 4632, 140, 1806, 102, 4405, 1651, 797, 2517, 140],\n",
              " [2597, 1446, 1906, 2542, 579, 4691],\n",
              " [3836, 3769, 242, 637, 1409, 4975, 2280, 200, 1529],\n",
              " [4441, 3228, 1990, 3234, 61, 4909, 3613, 1437, 1922, 4188, 2314],\n",
              " [992, 3206, 1408, 916, 1836, 934, 2388, 2542, 579, 4691],\n",
              " [1587, 4562, 1265, 2942, 1876, 3410],\n",
              " [4140, 4564, 3484, 3102],\n",
              " [1570, 4216, 118, 1183, 1923, 445, 2565, 4633, 2542, 579, 4691],\n",
              " [823, 2019, 4468, 3410, 3956, 1339, 3487, 1291, 2924, 1876],\n",
              " [1309, 569, 1318, 3682, 277, 541, 4161, 3845, 2542, 579, 4691],\n",
              " [3485, 2115, 3745, 4075, 388, 4808],\n",
              " [3741, 3326, 3032, 79, 2726, 1903, 4877, 4947, 1587, 4410, 2542, 579, 4691],\n",
              " [242, 4055, 4858, 1977, 4549, 4948],\n",
              " [2121, 4068, 4506, 1667, 4575, 4573, 3387, 2542, 579, 4691],\n",
              " [4236, 3273, 3340, 1706, 406, 4207, 1587, 3540, 3975],\n",
              " [708, 3024, 4389, 4101, 424, 620, 4204, 2669, 2008, 452],\n",
              " [823, 3273, 1876, 733, 3819, 966, 3571, 2542, 579, 4691],\n",
              " [3845, 3829, 4673, 4380, 1767, 1609, 3107],\n",
              " [536, 242, 503],\n",
              " [2503, 474, 288, 117, 1864, 847, 2943, 242, 3314],\n",
              " [2584, 4090, 3265, 1846, 4492, 1901, 1708, 2542, 579, 4691],\n",
              " [2049, 887, 4275, 3350, 4632, 2258, 1689, 2967, 387, 4275, 3544, 3663, 3515],\n",
              " [2429, 1924, 3463, 2875, 4572, 4340, 3273, 2542, 579, 4691],\n",
              " [3932,\n",
              "  684,\n",
              "  2696,\n",
              "  2069,\n",
              "  1424,\n",
              "  3766,\n",
              "  684,\n",
              "  2696,\n",
              "  2069,\n",
              "  1424,\n",
              "  3766,\n",
              "  3549,\n",
              "  3825,\n",
              "  1000,\n",
              "  1456],\n",
              " [4435, 933, 2688, 2770, 695, 1845, 793, 1654, 787, 1062, 1876, 102],\n",
              " [1727, 2647, 680, 3799, 1129, 3710, 4573, 424],\n",
              " [1096, 2642, 117, 4588, 4810, 987, 1566, 3394, 4659, 574],\n",
              " [1061, 4588, 2941, 3244, 725, 3050, 1761, 2503, 1113, 4808],\n",
              " [3256, 2019, 3592, 2728, 1842, 3671, 2382, 2540, 3741, 2542, 579, 4691],\n",
              " [4573, 3387, 242, 3024, 2924, 1876, 2015, 3240, 2542, 579, 4691],\n",
              " [3242, 767, 4964, 1776, 1761, 3390, 3394, 3558, 1354, 3340, 4052, 4331],\n",
              " [3741, 3326, 2881, 1169, 2542, 1798, 2542, 579, 4691],\n",
              " [2275, 2354, 3714, 4445, 1183, 3894, 4222, 2542, 579, 4691],\n",
              " [283, 1157, 415, 3826, 1079, 1619, 1703, 2116],\n",
              " [2924, 1876, 871, 3106, 2810, 3463, 3654],\n",
              " [1096, 1373, 3550, 2057, 3107, 2049, 2552, 2049, 2762, 3431, 2314],\n",
              " [1333, 3255, 4494, 2481, 654, 4068],\n",
              " [2153, 4065, 4465, 3524, 4502],\n",
              " [2129, 1454, 2027, 142, 2694],\n",
              " [2417, 129, 3090, 848, 402, 4389, 2314],\n",
              " [2229, 2658, 1876, 3771, 1854, 3175, 2900, 525, 1298, 2542, 579, 4691],\n",
              " [3904, 629, 2628, 1129, 268, 1854, 2032, 4844, 2314],\n",
              " [4078, 4458, 2813, 4342],\n",
              " [3252, 2748, 3187, 4410, 2097, 1511, 1145, 843, 450, 2542, 579, 4691],\n",
              " [4647, 3340, 1465, 2655, 3966, 2542, 579, 4691],\n",
              " [3900, 1049, 2618, 1835, 3894, 140, 1071],\n",
              " [1391, 1596, 2936, 139, 481],\n",
              " [3830, 655, 4506, 1912, 1291, 1876, 2705, 3637, 2621, 1619, 2186, 3848],\n",
              " [1485, 802, 4137, 3861, 3790, 1876, 424, 197, 2542, 579, 4691],\n",
              " [4657, 1876, 283, 16, 550, 61, 1366, 2828, 2019, 4867],\n",
              " [3632, 3748, 3956, 106, 2249, 141, 2542, 579, 4691],\n",
              " [118, 1702, 359, 1342, 4435, 8, 536, 3665, 2542, 579, 4691],\n",
              " [1654, 4650, 3748, 669, 4601, 4588, 3179, 4799, 4986],\n",
              " [1339, 1069, 4005, 2479, 3009, 1456],\n",
              " [2571, 2397, 1903, 1036, 1275, 2115, 4307, 360],\n",
              " [4921, 3251, 4158, 2599, 1587, 3670, 2052, 2481],\n",
              " [2503, 3222, 2329, 4366, 4673, 2413, 3301, 2542, 579, 4691],\n",
              " [3251, 424, 546, 4673, 3353, 305],\n",
              " [2941,\n",
              "  1876,\n",
              "  1658,\n",
              "  659,\n",
              "  175,\n",
              "  2258,\n",
              "  3826,\n",
              "  4021,\n",
              "  473,\n",
              "  1601,\n",
              "  884,\n",
              "  3670,\n",
              "  3357,\n",
              "  3390,\n",
              "  2314],\n",
              " [242, 3024, 1854, 117, 219, 1291, 342, 2618],\n",
              " [2823, 108, 1514, 4459, 1912, 2815, 2634],\n",
              " [3873, 644, 1111, 3937, 4269],\n",
              " [320, 1357, 3484, 1825, 3937, 793, 3484],\n",
              " [1552, 1380, 1401, 1854, 1129, 268, 3824, 935],\n",
              " [4657, 1876, 2180, 4341, 1456, 1235, 727],\n",
              " [2268, 2680, 1157, 2905, 2498, 2280, 2542, 579, 4691],\n",
              " [3297, 1694, 3663, 3515, 4673, 4593, 1416, 595, 914],\n",
              " [1876, 4174, 914, 1778, 1369, 3029, 2387, 4703, 2542, 579, 4691],\n",
              " [2314, 1113, 1391, 3228, 1204, 2314],\n",
              " [242, 2366],\n",
              " [2143, 595, 3750, 4795, 1590, 1650, 2304, 473],\n",
              " [2924, 1876, 3830, 3353, 621, 1360, 4573, 3387, 2542, 579, 4691],\n",
              " [1408, 2940, 4396, 1729, 1845, 1863, 1702, 2945, 552],\n",
              " [884, 1219, 4031, 3390, 3395, 1939, 4189, 898, 2314],\n",
              " [4820, 2501, 4588, 1879, 443, 4997, 1771],\n",
              " [3051, 3665, 1679, 1468, 892, 1249, 1062, 3075, 2314],\n",
              " [2149, 3174, 3796, 455, 3002, 2542, 579, 4691],\n",
              " [539, 2068, 270, 1030, 3054, 3957, 55, 1562, 4592, 197, 2314],\n",
              " [624, 2962, 3721, 4970, 2180, 2366, 4307, 722],\n",
              " [1876, 1727, 2833, 2331, 3047, 3956, 4414, 2542, 579, 4691],\n",
              " [2388, 1329, 1061, 856, 3699],\n",
              " [60, 4673, 3329, 1033, 2542, 579, 4691],\n",
              " [3932, 4548, 3156, 118, 3691],\n",
              " [2466, 1654, 3024, 686, 2943, 4042, 4201, 620, 742, 1876, 2490],\n",
              " [3252, 2846, 4217, 3107, 570, 3682, 2208, 1486, 2542, 579, 4691],\n",
              " [2564, 1783, 2035, 2349, 2515, 4696, 1527, 822, 568, 4144],\n",
              " [4770, 802, 2366, 2180, 4942, 2070, 2870, 1999, 4190],\n",
              " [1876, 268, 3467, 197, 3020, 4548, 1068, 843, 2542, 579, 4691],\n",
              " [2806, 1848, 2943, 1669, 3305],\n",
              " [3584, 3310, 3112, 419, 2268, 1012, 559],\n",
              " [4760, 2397, 4018, 3302, 4547, 4737, 2655],\n",
              " [2247, 2102, 3682, 2913],\n",
              " [1876, 3787, 2542, 4290, 3487, 3424, 2314],\n",
              " [4067, 2803, 2618, 1854, 1898, 1708, 3175, 1492, 277, 418],\n",
              " [3741, 4192, 3641, 2354, 3020, 1658, 4236, 4708, 2314],\n",
              " [3960, 795, 1651, 3769],\n",
              " [2388,\n",
              "  1937,\n",
              "  2993,\n",
              "  4612,\n",
              "  2913,\n",
              "  1456,\n",
              "  2563,\n",
              "  2679,\n",
              "  2873,\n",
              "  4915,\n",
              "  2913,\n",
              "  430,\n",
              "  3762,\n",
              "  2542,\n",
              "  579,\n",
              "  4691],\n",
              " [1648, 3565, 629, 242, 1931, 2180, 2032, 4942, 2070, 2870],\n",
              " [770, 4649, 4254, 4547, 1494, 471, 1010, 569, 2180, 2314],\n",
              " [2259, 1460, 4593, 3113, 4793, 4573, 2720],\n",
              " [1923, 1395, 4350, 2803, 2550, 1375, 1285, 524, 4620, 2542, 579, 4691],\n",
              " [172, 568, 2490, 242, 3024, 1761, 669, 3643, 2924, 1876, 2542, 579, 4691],\n",
              " [4328, 1113, 2542, 579, 4691, 1404, 2314, 1903, 1187, 2314],\n",
              " [2688, 2542, 3270, 4014, 1651, 4210, 2542, 579, 4691],\n",
              " [2956, 2749, 117, 2129, 3240, 3252, 4052, 4843, 1986],\n",
              " [3948, 3138, 2496, 3252, 4656, 755, 218, 3558, 2542, 579, 4691],\n",
              " [1903, 2540, 271, 1892, 1859],\n",
              " [1398, 4760, 1903, 3829, 4328, 1113, 141, 242, 3024],\n",
              " [2647, 3042, 812, 4145, 2600, 2957, 3741, 4804, 3911, 2542, 579, 4691],\n",
              " [1981, 1283, 1377, 4496, 2747, 1891, 4433, 4247],\n",
              " [3468,\n",
              "  4696,\n",
              "  2307,\n",
              "  1770,\n",
              "  4405,\n",
              "  2035,\n",
              "  4271,\n",
              "  3142,\n",
              "  3956,\n",
              "  4422,\n",
              "  2857,\n",
              "  1724,\n",
              "  4799],\n",
              " [2647, 978, 3465, 2571, 4691, 916, 2366, 3498, 1510, 2542, 579, 4691],\n",
              " [1408, 1010, 684, 2686, 2490, 2498, 4833],\n",
              " [3253, 3578, 3996, 373],\n",
              " [1587, 3340, 4848, 892, 3848, 4057, 2728, 2542, 579, 4691],\n",
              " [1543, 3255, 23, 4780, 210],\n",
              " [4643, 1692, 640, 1404, 3040, 4193, 3356, 4458],\n",
              " [3938, 457, 2354, 669, 1288, 4649, 2542, 579, 4691],\n",
              " [4394, 3390, 4869, 1582, 1010, 1619, 60, 3205, 4689],\n",
              " [1228, 4806, 4201, 1157, 2540, 3734, 2429, 1616, 1876, 2314],\n",
              " [3410, 1708, 4689, 2879, 207, 2568, 2101, 1604, 2952, 3845, 2314],\n",
              " [4520, 2669, 1898, 2475, 2631, 4247, 2811, 218, 2542, 579, 4691],\n",
              " [1959, 1409, 1699, 9, 2490, 242, 4299],\n",
              " [1424, 3624, 2730, 809, 2599, 3260],\n",
              " [820, 3805, 1540, 3525, 3741, 2669],\n",
              " [2788, 3076, 3618, 1419, 4435, 4932, 2417, 955, 277, 2539, 2314],\n",
              " [3252, 862, 1089, 3340, 3252, 4026, 3334, 4283, 2618, 2542, 579, 4691],\n",
              " [1876, 4331],\n",
              " [2554, 1291, 1604, 2820, 3569, 4987, 1298, 4599, 2542, 579, 4691],\n",
              " [1876, 1236, 1692, 4986, 1591, 2540, 1127, 559, 4548, 4808],\n",
              " [3365, 3748, 4112, 1408, 743, 3873, 4691, 3205, 2542, 579, 4691],\n",
              " [229, 2984, 4363, 976, 434, 2208, 620, 4054, 1010, 3400],\n",
              " [4493, 4155, 3273, 629, 2688, 277, 4689],\n",
              " [2662, 1603, 4587, 1894, 4686, 4137, 3563, 4216, 2542, 579, 4691],\n",
              " [2655, 3387, 1357, 2803, 3694, 4132, 3363],\n",
              " [165, 4808, 4374, 1957, 1535, 3985, 242],\n",
              " [4607, 2542, 3821, 992, 197, 1897, 3417, 2542, 579, 4691],\n",
              " [3024, 1987, 1555, 102, 1538],\n",
              " [242, 1062, 3197, 535, 3487, 3959, 1876, 2314],\n",
              " [2552, 3723, 4389, 4520, 1861, 4709, 1980, 60],\n",
              " [1425, 3912, 2131, 2107, 4601, 3498, 1897, 3410],\n",
              " [1494, 430, 388, 1244, 3160, 3780],\n",
              " [2987, 2488, 4649, 4, 4673, 4500, 2803, 2618, 982, 2314],\n",
              " [3186, 3500, 2435, 4732, 2745, 2184, 2542, 579, 4691],\n",
              " [1408, 2475, 4466, 656, 2275, 1406, 4574, 3239, 2542, 579, 4691],\n",
              " [1059, 2928, 400, 1415, 4673, 1333, 3403, 1912],\n",
              " [303, 4962, 3728, 1463, 1950, 3932, 242, 79, 4510],\n",
              " [3410, 1965, 3062, 369, 4713, 3213, 2542, 579, 4691],\n",
              " [4485, 3363, 1336, 4220, 3991, 2657, 2230],\n",
              " [2049, 2872, 4843, 3024, 2979],\n",
              " [2264, 4435, 534, 4057, 3248, 360, 2857, 3960],\n",
              " [3417, 2618, 671, 1876, 916, 197, 2542, 579, 4691],\n",
              " [4232, 2235, 2631, 4435, 1692, 1281, 4580, 3810, 359, 4808],\n",
              " [4328, 1113, 1876, 1897, 1366, 4857],\n",
              " [2873, 3767],\n",
              " [4657, 2687, 2160, 1071, 684, 3767, 2345, 2314],\n",
              " [4659, 141, 2281, 2542, 579, 4691],\n",
              " [3394, 1025, 415, 3723, 296, 1418, 475, 4399, 1745, 2559, 4201, 550],\n",
              " [3548, 1244, 966, 412],\n",
              " [793, 246, 686, 1535, 2498, 691, 1408, 3410],\n",
              " [2919, 3487, 3146, 1165, 2599, 2679, 2805, 4632],\n",
              " [4928, 2149, 1472, 3639, 2107, 4184, 1696, 242],\n",
              " [2413, 1980, 629, 274, 2618, 1834, 2542, 579, 4691],\n",
              " [734, 117, 4986, 2002, 4345, 4986, 3419, 3487, 2314],\n",
              " [3305, 4604, 2552, 3716, 4415, 2047, 190, 1511, 3286, 2097],\n",
              " [2657, 985, 4691, 1456, 4964, 1876, 1292, 3417, 2314],\n",
              " [3733, 4753, 3113, 117, 481, 481, 2542, 579, 4691],\n",
              " [242, 3024, 4214, 2924, 1876, 2542, 3818, 4, 4201, 370, 2542, 579, 4691],\n",
              " [2633, 283, 3985, 4989, 2924, 1876, 4530, 4573, 3387, 2542, 579, 4691],\n",
              " [1096, 467, 1892, 3465, 2571, 4588, 595, 2314],\n",
              " [3980, 2222, 2799, 1034, 3501, 4777, 2542, 579, 4691],\n",
              " [2242, 3487, 4629, 3273, 3631, 270, 2542, 579, 4691],\n",
              " [676, 2319, 758],\n",
              " [3747, 2924, 1876, 2259, 242, 939, 3175, 1937, 2256, 2542, 579, 4691],\n",
              " [3353, 2952, 2586, 1959, 836, 1727, 4370, 2542, 579, 4691],\n",
              " [4549, 119, 4021, 473, 3385, 2910, 3788, 4403, 2270, 2314],\n",
              " [1876, 4964, 1333, 2038, 4657, 4403, 3996, 2873, 3968, 3240],\n",
              " [2562, 1093, 2628, 4534, 2503, 251, 2686, 2542, 579, 4691],\n",
              " [1472, 3364, 2587, 4466, 4366, 3776, 4948, 1509, 644, 79, 2314],\n",
              " [884, 2811, 652, 4900, 119, 4307, 4703, 2314],\n",
              " [155,\n",
              "  4793,\n",
              "  2542,\n",
              "  2857,\n",
              "  4622,\n",
              "  3970,\n",
              "  2092,\n",
              "  3035,\n",
              "  1049,\n",
              "  1285,\n",
              "  1805,\n",
              "  2542,\n",
              "  579,\n",
              "  4691],\n",
              " [2924, 1876, 242, 3024, 55, 771, 4573, 3387, 2542, 579, 4691],\n",
              " [200, 4673, 2168, 4410, 4632, 2024, 2879, 1727, 3395, 2913, 2049, 730],\n",
              " [2631, 2329, 106, 3150, 242, 770],\n",
              " [716, 4289, 561, 2234],\n",
              " [1810, 1784, 1514, 4294, 4601, 4600, 4124, 4643, 1651, 797, 3525],\n",
              " [3592, 2979, 3845, 3252, 1511, 2074, 1815, 4286, 2542, 579, 4691],\n",
              " [2564, 1157, 2883, 1876, 254, 2083, 1854, 2019, 2508, 4955, 375, 2314],\n",
              " [3682, 630, 1458, 4585, 1879, 443, 1236, 1093, 1619],\n",
              " [1876, 4659, 1129, 268, 4160, 3477, 3336, 733, 2542, 579, 4691],\n",
              " [3932, 242, 3024, 2799, 4914, 3967, 1535, 3767, 686, 313],\n",
              " [3739, 1408, 1145, 4520, 3723, 242, 569, 2542, 1654, 686, 2943],\n",
              " [2924, 1876, 1499, 4691, 3240, 95, 1784, 4620, 4843, 2542, 579, 4691],\n",
              " [3373, 2962, 569, 1177, 661, 4541, 1360, 4759, 2111, 2559],\n",
              " [2722, 1536, 937, 1001, 1105, 902, 1897, 4654],\n",
              " [1876, 1727, 770, 313, 117, 1062, 1089, 3670, 1140, 55, 2542, 579, 4691],\n",
              " [3303, 453, 4468, 2429, 706, 4534, 2628, 578, 3030, 4808],\n",
              " [3230, 3487, 1386, 3327, 4287, 908, 3248, 3730, 2542, 579, 4691],\n",
              " ...]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "onehot_repr = [one_hot(words, VOCABULARY_SIZE) for words in corpus]\n",
        "onehot_repr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcRQcIrUZcn7"
      },
      "source": [
        "In the following lines, after encoding (0, 1) the words in the given corpus, the variable embedded_docs is created using the pad_sequences function from Keras. This step is essential when preparing text data for training neural network models like LSTM for natural language processing tasks.\n",
        "\n",
        "The onehot_repr list contains one-hot encoded representations of words in news article texts, and each inner list corresponds to a sequence. The padding='post' parameter ensures that padding is added to the end of each sequence, and maxlen specifies the desired sequence length after padding. The resulting embedded_docs array contains the transformed and padded sequences, forming the input data for the LSTM model.\n",
        "\n",
        "This preparation process is vital to maintain consistent sequence lengths required for neural network training and allows the data to be effectively fed into the LSTM model for further analysis and prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zVyMyIAZcn7",
        "outputId": "c1467766-13b2-4ec0-a21e-ad0484d92bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 473 3618 1727 ...    0    0    0]\n",
            " [   8  242 3024 ...    0    0    0]\n",
            " [1187 3959 4580 ...    0    0    0]\n",
            " ...\n",
            " [2134 3167 1036 ...    0    0    0]\n",
            " [3116 4057  536 ...    0    0    0]\n",
            " [1012 3637 4315 ...    0    0    0]]\n"
          ]
        }
      ],
      "source": [
        "embedded_docs = pad_sequences(onehot_repr, padding='post' ,maxlen=SENTENCE_LENGTH)\n",
        "print(embedded_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp7XU8PtZcn7"
      },
      "source": [
        "In the provided code and output, the array embedded_docs[0] represents the first sequence of word indices after one-hot encoding and padding. Each number in the array corresponds to the index of a word in the vocabulary, and this sequence has been padded with zeros to match a specified length (maxlen). This format is suitable for input into neural network models, such as LSTM, where each number indicates the word's presence in the text. The zeros represent the padding introduced to ensure uniform sequence lengths across all input samples. This processed array serves as a structured input for the subsequent stages of the LSTM model, enabling the analysis and prediction of the underlying patterns in the text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiub7461Zcn7",
        "outputId": "fa1bc6b8-8bf9-482b-a28a-d529427df32d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 473, 3618, 1727, 4573, 2019, 2770, 3378, 3947, 1178, 3403,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedded_docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYdRCqQxZcn7"
      },
      "source": [
        "### Neural Network Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUHgsnmkZcn8"
      },
      "source": [
        "As an option of design, the goal is to create a sequential neural network model for text classification, where the input text sequences are transformed through an embedding layer, passed through an LSTM layer to capture sequence information, and finally output a binary classification prediction. Dropout layers are used to mitigate overfitting during training.\n",
        "\n",
        "The model includes an embedding layer that transforms integer-encoded words into fixed-size vectors, followed by dropout layers to prevent overfitting.\n",
        "- An LSTM layer with 100 units captures sequential information, and another dropout layer is employed for regularization.\n",
        "- A dense layer with a sigmoid activation produces the final binary classification output.\n",
        "- The model is compiled with binary cross-entropy loss, the Adam optimizer, and accuracy as the evaluation metric.\n",
        "\n",
        "The model's architecture summary is printed, revealing layer configurations and parameter counts. This architecture enables the model to process input text data, capture context through LSTM, and make binary classification predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWRquJ7kZcn8",
        "outputId": "e8e29725-7af8-44e1-b7e4-4ddb0afb1be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 20, 40)            200000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20, 40)            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               56400     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,501\n",
            "Trainable params: 256,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(VOCABULARY_SIZE,EMBEDDING_VECTOR_FEATURES,input_length=SENTENCE_LENGTH))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcmGmG5jZcn8"
      },
      "source": [
        "### Tranining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pAnB9JnZcn8"
      },
      "source": [
        "Now, before training process, we must prepare the input for the neural network.\n",
        "\n",
        "In the provided code, X_final represents the final numpy array of embedded documents obtained after processing the text data through the one-hot encoding and padding steps. This array contains sequences of word indices, each corresponding to a processed text.\n",
        "\n",
        "Additionally, Y_final contains the labels associated with the training dataset\n",
        "\n",
        "This processed data can now be used for testing and evaluating the LSTM model's performance on detecting fake news."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5XM8YPxTZcn8"
      },
      "outputs": [],
      "source": [
        "X_final = np.array(embedded_docs)\n",
        "Y_final = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OlnaocJpZcn8"
      },
      "outputs": [],
      "source": [
        "# Data split\n",
        "X_train_embed, X_test_embed, Y_train_embed, Y_test_embed = train_test_split(X_final, Y_final, test_size=TEST_RATIO, random_state=27)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2E0QzQFZcn8"
      },
      "source": [
        "The provided code snippet trains a sequential neural network model using TensorFlow.\n",
        "\n",
        "The model architecture consists of an embedding layer followed by a dropout layer, a Long Short-Term Memory (LSTM) layer with 100 units, another dropout layer, and a dense layer with a sigmoid activation function.\n",
        "\n",
        "The model is compiled with the binary cross-entropy loss function and the Adam optimizer. The training data X_train_embed and Y_train_embed are used for training, and the validation data X_test_embed and Y_test_embed are used for validation. T\n",
        "\n",
        "The model is trained over 20 epochs, with each batch containing 64 samples. This combination of architecture, loss function, optimizer, and training configuration is designed to achieve high accuracy in binary classification tasks, possibly like detecting fake news or other similar tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFdfAZDAZcn8"
      },
      "source": [
        "The choice of the number of epochs and batch size in training a neural network depends on various factors and needs to be fine-tuned based on the specific problem and dataset.\n",
        "\n",
        "In the given code, the model is trained using the fit() function with 20 epochs and a batch size of 64.\n",
        "\n",
        " - 20 Epochs:\n",
        "Using 20 epochs means that the entire dataset will be iterated through the neural network 20 times during training. More epochs can potentially allow the model to learn more complex patterns from the data. However, increasing the number of epochs may also lead to overfitting, where the model becomes too specialized to the training data and performs poorly on new, unseen data. The choice of 20 epochs could be based on empirical observations that the model's validation performance tends to stabilize or converge within this range.\n",
        "\n",
        "- Batch Size of 64:\n",
        "The batch size determines the number of training samples that are propagated through the network before updating the model's weights. Smaller batch sizes (e.g., 32, 64) can lead to more frequent updates and potentially faster convergence, as the model updates its parameters more often. However, smaller batch sizes can also result in noisy gradients and slower training on hardware with high parallelism (like GPUs). Larger batch sizes (e.g., 128, 256) can provide more stable gradient estimates but might take longer to update the model.\n",
        "\n",
        "In practice, the optimal values for epochs and batch size can vary depending on factors like the complexity of the dataset, the architecture of the model, available computing resources, and the presence of regularization techniques. It's common to try different values and monitor the model's performance on validation data to determine the best combination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdiSedhXZcn8",
        "outputId": "3dd85a15-bd0e-42dc-e0f9-af54eead0f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "200/200 [==============================] - 7s 28ms/step - loss: 0.3298 - accuracy: 0.8364 - val_loss: 0.1947 - val_accuracy: 0.9169\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 4s 22ms/step - loss: 0.1513 - accuracy: 0.9408 - val_loss: 0.1992 - val_accuracy: 0.9214\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 5s 25ms/step - loss: 0.1095 - accuracy: 0.9586 - val_loss: 0.2228 - val_accuracy: 0.9180\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 5s 23ms/step - loss: 0.0886 - accuracy: 0.9691 - val_loss: 0.2376 - val_accuracy: 0.9074\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 4s 22ms/step - loss: 0.0702 - accuracy: 0.9763 - val_loss: 0.2890 - val_accuracy: 0.9152\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 5s 26ms/step - loss: 0.0563 - accuracy: 0.9807 - val_loss: 0.2806 - val_accuracy: 0.9151\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 4s 22ms/step - loss: 0.0409 - accuracy: 0.9878 - val_loss: 0.3277 - val_accuracy: 0.9131\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 5s 25ms/step - loss: 0.0382 - accuracy: 0.9864 - val_loss: 0.3264 - val_accuracy: 0.9050\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 5s 24ms/step - loss: 0.0308 - accuracy: 0.9890 - val_loss: 0.3571 - val_accuracy: 0.9096\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 5s 26ms/step - loss: 0.0306 - accuracy: 0.9900 - val_loss: 0.3899 - val_accuracy: 0.9092\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 5s 26ms/step - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.3697 - val_accuracy: 0.9101\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 4s 22ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.4799 - val_accuracy: 0.9047\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 5s 26ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.5547 - val_accuracy: 0.8968\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 4s 22ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.4701 - val_accuracy: 0.9081\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 4s 22ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.4916 - val_accuracy: 0.9059\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 5s 26ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.5183 - val_accuracy: 0.9083\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 4s 22ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.5481 - val_accuracy: 0.9045\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 5s 26ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.5107 - val_accuracy: 0.9039\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 5s 23ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.5041 - val_accuracy: 0.9054\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 4s 22ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5417 - val_accuracy: 0.9090\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7cd78dfe2a10>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model trained with Tensorflow\n",
        "model.fit(X_train_embed, Y_train_embed, validation_data = (X_test_embed,Y_test_embed), epochs=TRAINING_EPOCHS, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dOBXKu3UZcn8"
      },
      "outputs": [],
      "source": [
        "# Save the model to a file\n",
        "model.save('lstm_model_fake_news.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab1EYsfYZcn9"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiQWB1V0Zcn9",
        "outputId": "2efa46b8-23c3-43ed-e273-64736c3af755"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1943,  658, 4025, ...,    0,    0,    0],\n",
              "       [1408,  708, 1291, ...,    0,    0,    0],\n",
              "       [1408, 1456, 3047, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 695, 3024,  568, ...,    0,    0,    0],\n",
              "       [2542, 4329, 2946, ...,    0,    0,    0],\n",
              "       [1228,  242, 2062, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9ytlPrfZcn9",
        "outputId": "1ce35910-34b8-4165-bd74-608949fa6745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 2s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = (model.predict(X_test_embed) > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QDWsaHkdKMJ",
        "outputId": "887051ac-42f8-4c25-edea-2930c87b36b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       ...,\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]], dtype=int32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEvOf2_YZcn9"
      },
      "source": [
        "### Visualizations and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2-RHl_hZcn9",
        "outputId": "7ffbbb6b-5297-4fc0-e0fa-32a96e9da8c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9090411957710536"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(Y_test_embed,predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BxBT6rVd3qm",
        "outputId": "db94cf80-b1b4-4880-e21d-30d1b0181d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 2s 4ms/step - loss: 0.5417 - accuracy: 0.9090 - precision: 0.8936 - recall: 0.8992\n",
            "Loss: 0.5416796803474426\n",
            "Accuracy: 0.909041166305542\n",
            "Precision: 0.8935818076133728\n",
            "Recall: 0.8991666436195374\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "# Evaluate the model on test data\n",
        "results = model.evaluate(X_test_embed, Y_test_embed)\n",
        "\n",
        "loss = results[0]\n",
        "accuracy = results[1]\n",
        "precision = results[2]\n",
        "recall = results[3]\n",
        "\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQAWLo1v_yBW"
      },
      "source": [
        "### Improving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JrXx22F_yBW",
        "outputId": "1525bd33-153a-4998-e179-d0c575ab9208"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 03m 44s]\n",
            "val_accuracy: 0.9214843511581421\n",
            "\n",
            "Best val_accuracy So Far: 0.9253906011581421\n",
            "Total elapsed time: 00h 23m 46s\n",
            "Mejores hiperparámetros: {'dropout': 0.38740223810710805, 'units': 100}\n"
          ]
        }
      ],
      "source": [
        "# Definir la función del modelo que deseas ajustar\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Embedding(VOCABULARY_SIZE, EMBEDDING_VECTOR_FEATURES, input_length=SENTENCE_LENGTH))\n",
        "    model.add(keras.layers.Dropout(hp.Float('dropout', min_value=0.2, max_value=0.5, default=0.3)))\n",
        "    model.add(keras.layers.LSTM(hp.Int('units', min_value=50, max_value=200, step=50, default=100)))\n",
        "    model.add(keras.layers.Dropout(hp.Float('dropout', min_value=0.2, max_value=0.5, default=0.3)))\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Inicializar el optimizador de búsqueda\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,  # Número de combinaciones a probar\n",
        "    directory='my_dir',  # Directorio para almacenar resultados\n",
        "    project_name='my_project'\n",
        ")\n",
        "\n",
        "# Realizar la búsqueda de hiperparámetros\n",
        "tuner.search(X_train_embed, Y_train_embed, epochs=20, validation_split=0.2)\n",
        "\n",
        "# Imprimir los mejores hiperparámetros encontrados\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Mejores hiperparámetros: {best_hps.values}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7mYjMTtw_74d"
      },
      "outputs": [],
      "source": [
        "BEST_VOCABULARY_SIZE = 5000\n",
        "BEST_EMBEDDING_VECTOR_FEATURES = 40\n",
        "BEST_SENTENCE_LENGTH = 20\n",
        "BEST_DROPOUT_RATE = 0.3874\n",
        "BEST_LSTM_UNITS = 100\n",
        "BEST_LEARNING_RATE = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1RqH2bFT_yBW"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(BEST_VOCABULARY_SIZE, BEST_EMBEDDING_VECTOR_FEATURES, input_length=BEST_SENTENCE_LENGTH))\n",
        "model.add(Dropout(BEST_DROPOUT_RATE))\n",
        "model.add(Bidirectional(LSTM(BEST_LSTM_UNITS, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(BEST_LSTM_UNITS)))\n",
        "model.add(Dropout(BEST_DROPOUT_RATE))\n",
        "model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFhMX_5K_yBW",
        "outputId": "b6d63312-d323-4bb9-93c2-f4ef036738fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 20, 40)            200000    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 20, 40)            0         \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 20, 200)          112800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 200)              240800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 553,801\n",
            "Trainable params: 553,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=BEST_LEARNING_RATE)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmuGPQ1N_yBX",
        "outputId": "7ae297f6-2cfd-4890-e9ba-ee26eca1523a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "200/200 [==============================] - 27s 104ms/step - loss: 0.3172 - accuracy: 0.8554 - val_loss: 0.1966 - val_accuracy: 0.9187\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 20s 102ms/step - loss: 0.1528 - accuracy: 0.9441 - val_loss: 0.1960 - val_accuracy: 0.9178\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 31s 156ms/step - loss: 0.1172 - accuracy: 0.9576 - val_loss: 0.2172 - val_accuracy: 0.9196\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0905 - accuracy: 0.9698 - val_loss: 0.2462 - val_accuracy: 0.9151\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 22s 108ms/step - loss: 0.0813 - accuracy: 0.9737 - val_loss: 0.2622 - val_accuracy: 0.9149\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 27s 137ms/step - loss: 0.0637 - accuracy: 0.9819 - val_loss: 0.2708 - val_accuracy: 0.9162\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 20s 99ms/step - loss: 0.0616 - accuracy: 0.9827 - val_loss: 0.2591 - val_accuracy: 0.9110\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 20s 102ms/step - loss: 0.0574 - accuracy: 0.9829 - val_loss: 0.3159 - val_accuracy: 0.9178\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.0454 - accuracy: 0.9878 - val_loss: 0.3127 - val_accuracy: 0.9180\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 29s 144ms/step - loss: 0.0406 - accuracy: 0.9902 - val_loss: 0.3317 - val_accuracy: 0.9171\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 25s 123ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.3893 - val_accuracy: 0.9118\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0356 - accuracy: 0.9911 - val_loss: 0.3350 - val_accuracy: 0.9141\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 20s 102ms/step - loss: 0.0333 - accuracy: 0.9918 - val_loss: 0.3176 - val_accuracy: 0.9151\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 21s 107ms/step - loss: 0.0321 - accuracy: 0.9923 - val_loss: 0.3629 - val_accuracy: 0.9129\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 19s 98ms/step - loss: 0.0316 - accuracy: 0.9919 - val_loss: 0.3515 - val_accuracy: 0.9138\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 20s 102ms/step - loss: 0.0270 - accuracy: 0.9937 - val_loss: 0.3888 - val_accuracy: 0.9123\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 20s 102ms/step - loss: 0.0263 - accuracy: 0.9936 - val_loss: 0.3476 - val_accuracy: 0.9132\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 20s 101ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.3435 - val_accuracy: 0.9123\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 20s 102ms/step - loss: 0.0203 - accuracy: 0.9958 - val_loss: 0.4027 - val_accuracy: 0.9098\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 21s 105ms/step - loss: 0.0228 - accuracy: 0.9947 - val_loss: 0.3882 - val_accuracy: 0.9116\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_embed, Y_train_embed, validation_data = (X_test_embed,Y_test_embed), epochs=TRAINING_EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGupt6AY_yBX",
        "outputId": "839e9cb6-548d-4d8d-c6fc-e8fae7ef309d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 3s 13ms/step\n",
            "Confusion Matrix:\n",
            "[[2814  272]\n",
            " [ 213 2187]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92      3086\n",
            "           1       0.89      0.91      0.90      2400\n",
            "\n",
            "    accuracy                           0.91      5486\n",
            "   macro avg       0.91      0.91      0.91      5486\n",
            "weighted avg       0.91      0.91      0.91      5486\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "y_pred = (model.predict(X_test_embed) > 0.5).astype(\"int32\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(Y_test_embed, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(Y_test_embed, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DVbFNmiPX2O",
        "outputId": "0fd3abe2-fc00-47d7-b901-f4c3bf501b4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de notificias verdaderas: 3027\n",
            "Número de notificias falsas: 2459\n"
          ]
        }
      ],
      "source": [
        "# Contar cuántos elementos son cero\n",
        "count_zeros = y_pred.size - np.count_nonzero(y_pred)\n",
        "\n",
        "print(f\"Número de notificias verdaderas: {count_zeros}\")\n",
        "print(f\"Número de notificias falsas: {np.count_nonzero(y_pred)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PkhpczgoQKKJ"
      },
      "outputs": [],
      "source": [
        "model.save('best_hiperparameters_lstm_model_fake_news.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h9hNdmDZcn9"
      },
      "source": [
        "### Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_bEHA5KZcn9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
