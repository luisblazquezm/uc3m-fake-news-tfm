{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAKE NEWS DETECTOR - ENSEMBLE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLAN OF ACTION\n",
    "\n",
    "- Load the dataset, i.e. combine it into one, and create true / false labels\n",
    "- Then, utilizing HuggingFace's Transformers library, retrieve the pre-trained BERT model to use as the foundation of a Fake News Detection Model. BERT has incredible language understanding abilities. As a result, it will help the model better grasp news context and hence generate educated predictions about whether news is false or not - The Base Model and general architecture are then defined. For example, we may use PyTorch to define, train, and evaluate neural network models.\n",
    "- After that, we freeze the weights on the BERT beginning layers. If we do not accomplish this, we will lose all of our past knowledge.\n",
    "- Next, we add new Trainable Layers. In general, feature extraction layers are the only information from the basic model that we utilize. We must add additional layers on top of the model to forecast its particular jobs. Furthermore, we establish a new output layer because the pre-trained model's ultimate output will almost definitely differ from the result we desire for our model, which is binary 0 and 1.\n",
    "- The final stage is to fine-tune our model. Making minor tweaks to the model to improve it.\n",
    "- After that, we use our Fake News Detection Model on unseen data to create predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.0.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install nltk\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "\n",
    "#### Scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#### Others\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_1_PATH = \"./data/ensemble_learning/dataset1/\"\n",
    "DATA_BASE_2_PATH = \"./data/ensemble_learning/dataset2/\"\n",
    "NUM_RECORDS_TO_SAMPLE = 3000\n",
    "TRAIN_RATIO = 0.7\n",
    "TEST_RATIO = 0.3\n",
    "PYTORCH_BATCHS_SIZE = 32\n",
    "TRAINING_EPOCHS = 2 # Number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset chosen comes from Kaggle: https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset. \n",
    "\n",
    "It has two separate .csv files, one having the real news, called \"True.csv\" and another one, having the fake news, called \"Fake.csv\". Both files have the exact same data form.\n",
    "\n",
    "They both include the title of the news, the entire news article text, the subject, which is basically the category of news and the date on which it was published. \n",
    "\n",
    "We must now put them together if we are to conduct training and testing.\n",
    "\n",
    "Let us begin by importing pandas.\n",
    "\n",
    "The two csv files are converted into pandas dataframes and named.\n",
    "\n",
    "A categorization column is required to determine if a record is false news or not. We create a new column named classification and set all of its entries to 1 with the command fake['classification'] = 1. Our classifier will detect bogus news and assign it a value of one.\n",
    "\n",
    "The index counts of the two dataframes are then reset by setting the option ignore_index to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "true_data = pd.read_csv(DATA_BASE_1_PATH + 'True.csv')\n",
    "fake_data = pd.read_csv(DATA_BASE_1_PATH + 'Fake.csv')\n",
    "\n",
    "# Adding classification column\n",
    "fake_data['classification'] = 1\n",
    "true_data['classification'] = 0\n",
    "\n",
    "# Concatenate two dataframes together\n",
    "true_fake = pd.concat([true_data,fake_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of data exploration is to visualize data in order to conduct a more in-depth research, find early insights, and detect trends. We might begin by simply charting the amount of news items in each category:\n",
    "\n",
    "When we import matplotlib, a new variable called category_dist is created that counts the number of times the numbers 1 and 0 appear within the classification column. Using plt and a series of commands, we can select the size, type of chart, color, labels, title, and whether or not we want the gridlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Counting values within each classification bucket\n",
    "category_dist = true_fake['classification'].value_counts()\n",
    "\n",
    "# Defining chart\n",
    "plt.figure(figsize=(8,6))\n",
    "category_dist.plot(kind='bar', color = '#89b4a1')\n",
    "plt.xlabel(\"Classification\", fontsize = 12)\n",
    "plt.ylabel(\"Number of News Headlines by Classification\", fontsize = 12)\n",
    "plt.title(\"Distribution of News Headlines by Classification\", fontsize = 15)\n",
    "plt.grid(False)\n",
    "\n",
    "# Generating chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe contains around 40.000 records, with somewhat more bogus news. We don't need to use any unbalanced data treatment strategies like upsampling because the difference is so small.\n",
    "\n",
    "Feeding the model selection pipeline with more than 40.000 records, each of which has 750 words or more, may result in a RAM memory overflow. A easy method is to choose a smaller percentage of the records.\n",
    "\n",
    "Pandas provides an easy-to-use command that allows the developer to sample a defined number of records while creating a random_state for repeatability of findings. I chose 3000 records since it is an arbitrary amount that represents slightly less than 10% of the dataframe and should not create RAM overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = true_fake.sample(NUM_RECORDS_TO_SAMPLE, replace=True, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Counting values within each classification bucket\n",
    "category_dist_sample = sample_df['classification'].value_counts()\n",
    "\n",
    "# Defining chart\n",
    "plt.figure(figsize=(8,6))\n",
    "category_dist_sample.plot(kind='bar', color = '#89b4a1')\n",
    "plt.xlabel(\"Classification\", fontsize = 12)\n",
    "plt.ylabel(\"Number of News Headlines by Classification\", fontsize = 12)\n",
    "plt.title(\"Distribution of News Headlines by Classification\", fontsize = 15)\n",
    "plt.grid(False)\n",
    "\n",
    "# Generating chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with 3000 records, the distribution between fake and truthful news stays the same. This means we can move on to the next phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another dataset only for testing purposes will be used to deploy the model on unseen data. Records were scraped from 244 websites based on the categorization of a Chrome Extension called BS Detector. You can find the dataset at the following link (https://www.kaggle.com/datasets/mrisdal/fake-news). The major difference is that this one contains only fake reviews. It has 21 columns in total, among which the most relevant are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import genuine and fake csv files into a pandas dataframe. Then, in the 'Target' column, we insert the labels True / Fake. Finally, we use random mixing to combine the two dataframes into a single dataframe.\n",
    "\n",
    "For the classification problem, for the three datasets, we only need text and information on whether the news is truthful or not correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text cleansing is essential in NLP. Stopwords, special characters, and HTML elements all add unnecessary complexity to the processing of our models.\n",
    "\n",
    "Eliminating all of the above may result in a reduction in training and testing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14100    MOSCOW/PARIS (Reuters) - The Kremlin said on W...\n",
      "3491     WASHINGTON (Reuters) - A political feud erupte...\n",
      "25773    Just because Vermont Senator Bernie Sanders is...\n",
      "4180     LONDON (Reuters) - The United States first ta...\n",
      "19183    RIYADH (Reuters) - Saudi Arabia is celebrating...\n",
      "                               ...                        \n",
      "24009    Things got very uncomfortable for Jason Chaffe...\n",
      "32426     It is absolutely unbelievable that he could b...\n",
      "11283    DUBAI (Reuters) - Kuwait s deputy foreign mini...\n",
      "22101    Before Donald Trump stepped foot in the White ...\n",
      "11568    RIYADH (Reuters) - Saudi Arabia announced on F...\n",
      "Name: text, Length: 3000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Sample text cleaning functions\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    cleaned_text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Remove special characters and punctuations except for periods and exclamation marks\n",
    "    cleaned_text = re.sub(r'[^\\w\\s.!?]', '', cleaned_text)\n",
    "\n",
    "    # Remove extra whitespaces and newlines\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Get the list of English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Remove stopwords\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    # Join the filtered words back to form a cleaned text\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "print(sample_df['text'])\n",
    "\n",
    "# Applying text cleaning and preprocessing to 'text' column\n",
    "sample_df['text'] = sample_df['text'].apply(clean_text)\n",
    "sample_df['text'] = sample_df['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate (Model Selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the project, I considered 7 common classification models, including parametric and non-parametric ones. All of them are supervised, learning models:\n",
    "\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "- k-Nearest-Neighbours (kNN)\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Logistic regression (LR)\n",
    "- Decision tree classifier (CART)\n",
    "- Support Vector Machines (SVM)\n",
    "- Linear SVM\n",
    "- Random Forest\n",
    "- GBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to put the model selection process into action. The code runs data through a count vectorizer and all of the previously mentioned models before doing k-fold cross-validation. After that, the average accuracy is determined and displayed in a boxplot chart. Let's take it one step at a time:\n",
    "\n",
    "\n",
    "- scikit-learn and matplotlib are these the only two libraries required? Sklearn contains all of the functions required for doing machine learning on data. Every model is imported using a \"sub-library\": LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier, SVC, GaussianNB, and LinearDiscriminantAnalysis are all examples of classification algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At this point, we may specify the input and target variables based on the data. The input variable xis \"text,\" which contains the review corpus; the output variable yis \"classification,\" which displays the labels 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining input and target variable\n",
    "x_input = sample_df['text']\n",
    "y_target = sample_df['classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We know that some of the models under consideration, such as decision tree classifiers, require a dense matrix. Dense matrices have a high proportion of non-zero values. To avoid errors, the ToDenseTransformerclass ensures that all matrices are dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding To Dense Transfomer to satisfy dense data requirement\n",
    "class ToDenseTransformer(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return X.todense()\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The list models is then constructed, and each model's object is appended to the list. The list results, on the other hand, will include all of the distinct model scores linked with their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(max_iter=10000)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The k-fold option specifies the number of k-folds desired. The notion of cross-validation is introduced here. Cross-validation tries to improve model accuracy estimation. It is known as k-fold cross validation, where k is the number of sub-groups into which the data is separated. The model is trained on a subset of the data and then tested on the remainder k-1. The accuracy is calculated on the average score.\n",
    "\n",
    "- The pipeline runs cross-validation on the k-fold of choice and applies the count vectorizer, dense transformer, and model of choice. The findings are then printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the modified ToDenseTransformer class\n",
    "class ToDenseTransformer:\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "LogisticRegression(max_iter=10000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[0;32m---> 12\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_selection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(cv_results)\n\u001b[1;32m     14\u001b[0m names\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 420\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1302\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1300\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1302\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1327\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:452\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    448\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[1;32m    449\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[1;32m    450\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[1;32m    451\u001b[0m ]\n\u001b[0;32m--> 452\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    461\u001b[0m     solver,\n\u001b[1;32m    462\u001b[0m     opt_res,\n\u001b[1;32m    463\u001b[0m     max_iter,\n\u001b[1;32m    464\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    465\u001b[0m )\n\u001b[1;32m    466\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_lbfgsb_py.py:361\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    355\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 71\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_linear_loss.py:292\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    290\u001b[0m     grad[:n_features] \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m grad_pointwise \u001b[38;5;241m+\u001b[39m l2_reg_strength \u001b[38;5;241m*\u001b[39m weights\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[0;32m--> 292\u001b[0m         grad[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_pointwise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m     grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n_classes, n_dof), dtype\u001b[38;5;241m=\u001b[39mweights\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:47\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "\n",
    "#Building pipeline and gathering results\n",
    "for name, model in models:\n",
    "    classifier = Pipeline([('vect', CountVectorizer(strip_accents=None, lowercase = False, preprocessor = None)), ('todense', ToDenseTransformer()), (name, model)])\n",
    "    print(name)\n",
    "    print(model)\n",
    "    cv_results = model_selection.cross_val_score(classifier, x_input, y_target, cv=kfold, scoring=scoring, error_score='raise')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: Average accuarcy = %f (Variance = %f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, matplotlib creates a boxplot chart to help us analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A boxplot provides information on five crucial accuracy statistics for our models:\n",
    "\n",
    "- the bare minimum\n",
    "- first quartile (25th percentile)\n",
    "- the average (second quartile)\n",
    "- third quartile (75th percentile)\n",
    "- the very best.\n",
    "\n",
    "All of the models used for cross-validation are plotted on the x-axis. Instead, we have the accuracy score on the y-axis. From the chart alone, its hard to tell exactly how well each model performed; for example, the logistic regression and the decision tree classifier are very close to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>>>>>>>>>>>>>>> NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART is the best performer in terms of accuracy but the logistic regression is slightly better (by a very thin margin) at delivering consistent results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving models (Hyperparamenter tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is one of the two models with the best accuracy and lowest variance, making it an excellent option for hyperparameter optimization.\n",
    "\n",
    "The logistic regression model's two parameters are as follows:\n",
    "\n",
    "- A solver is an algorithm that aids the model's adaptation to data. There are five forms of logistic regression: liblinear, lbfgs, newton-cg, sag, and saga.\n",
    "\n",
    "- The regularization strength is expressed by the C parameter. A larger number for C indicates more regularization. When the model is supplied with previously unknown data, regularization is synonymous with generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code optimizes the above hyperparameters as well as the count vectorizer parameters IN ORDER TO FIND THE BEST PARAMETERS FOR COUNT VECTORIZER AND LOGISTIC REGRESSION MODEL:\n",
    "\n",
    "- Libraries had previously been imported in the previous code cell, but I opted to re-import them to make this code sample self-contained. In this situation, we simply require sklearn with cross-validation, model deployment, pipelining, and count vectorizer sub-packages.\n",
    "\n",
    "- This time, the pipeline just contains the count vectorizer and the logistic regression model. There is no need for a thick transformer.\n",
    "\n",
    "- Moving on, the parameters list contains all of the potential hyperparameter combinations that the grid_search tries for each component of the pipeline. The parameter max_df of the Count, Vectorizer, for example, is in charge of the model's generalization.\n",
    "\n",
    "- A max_df eliminates words that appear too often, and a max_df of 0.7 removes words that appear too frequently, concretely in more than 70% of the documents. In one scenario vect__max_df will combine a max_df of 0.7 with a ngram_range of (1,1), using a kernel poly and a C parameter of 10. The total fits (combinations) are 405 because each cross-validation is performed 5 times.\n",
    "\n",
    "- The final section of code begins reporting the results on the console when calculations are conducted after starting grid_search.fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Pipeline with CountVectorizer and LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('LR', LogisticRegression(max_iter = 10000))\n",
    "])\n",
    "\n",
    "# Defining hyperparameters\n",
    "parameters = {\n",
    "    'vect__max_df':[0.7,0.8,0.9],\n",
    "    'vect__ngram_range':  [(1,1), (1,2), (1,3)],\n",
    "    'LR__solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'LR__C': [100, 10, 1.0, 0.1]\n",
    "}\n",
    "\n",
    "# Define grid search\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(pipeline, param_grid=parameters, refit = True, verbose = 3, cv=5)\n",
    "grid_result = grid_search.fit(x_input.values.astype('U'), y_target.values.astype('U'))\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- C = 100\n",
    "- type of kernel = liblinear\n",
    "- max_df = 0.7\n",
    "- ngram_range = (1, 3)\n",
    "\n",
    "With the settings, the model achieves a 98% accuracy when deploying the cross-validation method on only 3000 news. The result is already extremely promising. Given the optimal hyperparameters such as C and max_df, we can already tell the generalization of the algorithm should be enough to correctly classify unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Decision Tree Classifier (CART)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree Classifier (CART) has the highest accuracy of the six methods studied. It should perform even better after hyperparameter adjustment.\n",
    "\n",
    "The CART model has three parameters:\n",
    "\n",
    "- max_features is \"the number of features to consider each time to make the split decision\". If the data collection has 50 columns, you may set this option to 10 to include just 10 of them during the training phase.\n",
    "\n",
    "- max_depth as the greatest number of \"ramifications\" a tree can have is specified by max_depth. A greater number may result in overfitting.\n",
    "\n",
    "- min_samples_leaf is defined as \"the minimum number of samples required to be present at a leaf node\". The value determines how many split points the tree must have.\n",
    "There are no additional parameters than hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Pipeline with CountVectorizer and LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('CART', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Defining hyperparameters\n",
    "parameters = {\n",
    "    'vect__max_df':[0.7,0.8,0.9],\n",
    "    'vect__ngram_range':  [(1,1), (1,2), (1,3)],\n",
    "    'CART__max_features': [0.2, 0.4, 0.6, 0.8],\n",
    "    'CART__max_depth': [3,4,5,6],\n",
    "    'CART__min_samples_leaf': [0.04, 0.06, 0.08]\n",
    "}\n",
    "\n",
    "# Define grid search\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(pipeline, param_grid=parameters, refit = True, verbose = 3, cv=5)\n",
    "grid_result = grid_search.fit(x_input.values.astype('U'), y_target.values.astype('U'))\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_depth = 4\n",
    "- max_features = 0.8\n",
    "- min_sample_leaf = 0.04\n",
    "- max_df = 0.7\n",
    "- ngram_range = (1, 1)\n",
    "\n",
    "With the above hyperparameters for the count vectorizer and the algorithm, the average accuracy reaches a 99% score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>>>>>>>>>>>>>>>> NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we deploy the model on the 40.000 records and test it on 9000, the accuracy stays the same. A 99% precision remains a great achievement, on the other hand, though, 1% of approximately 4000 records has been misclassified, and the logistic regression seems overall a better solution for deployment on new records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate (logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisin del modelo en el conjunto de prueba: 98.44%\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Dividir los datos en conjuntos de entrenamiento y prueba (70 - 30)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_input.values.astype('U'), y_target.values.astype('U'), test_size=0.3, random_state=42)\n",
    "\n",
    "# Paso 2: Inicializar el modelo con los mejores hiperparmetros encontrados\n",
    "best_params = {\n",
    "    'vect__max_df': 0.7,\n",
    "    'vect__ngram_range': (1, 3),\n",
    "    'LR__C': 100,\n",
    "    'LR__solver': 'liblinear'\n",
    "}\n",
    "\n",
    "best_model = Pipeline([\n",
    "    ('vect', CountVectorizer(max_df=best_params['vect__max_df'], ngram_range=best_params['vect__ngram_range'])),\n",
    "    ('LR', LogisticRegression(C=best_params['LR__C'], solver=best_params['LR__solver'], max_iter=10000))\n",
    "])\n",
    "\n",
    "# Paso 3: Entrenar el modelo con los datos de entrenamiento\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "# Paso 4: Hacer predicciones en el conjunto de prueba\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "# Calcular la precisin del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisin del modelo en el conjunto de prueba: {:.2f}%\".format(accuracy*100))\n",
    "\n",
    "#filename = 'logistic_regression_model.sav'\n",
    "#pickle.dump(best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate (decision tree classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisin del modelo en el conjunto de prueba: 98.11%\n"
     ]
    }
   ],
   "source": [
    "# Paso 2: Inicializar el modelo con los mejores hiperparmetros encontrados\n",
    "best_params = {\n",
    "    'vect__max_df': 0.7,\n",
    "    'vect__ngram_range': (1,1),\n",
    "    'CART__max_features': 0.8,\n",
    "    'CART__max_depth': 4,\n",
    "    'CART__min_samples_leaf': 0.04\n",
    "}\n",
    "\n",
    "most_precise_model = Pipeline([\n",
    "    ('vect', CountVectorizer(max_df=best_params['vect__max_df'], ngram_range=best_params['vect__ngram_range'])),\n",
    "    ('CART', DecisionTreeClassifier(\n",
    "        min_samples_leaf=best_params['CART__min_samples_leaf'], \n",
    "        max_features=best_params['CART__max_features'],\n",
    "        max_depth=best_params['CART__max_depth'])\n",
    "    )\n",
    "])\n",
    "\n",
    "# Paso 3: Entrenar el modelo con los datos de entrenamiento\n",
    "most_precise_model.fit(x_train, y_train)\n",
    "\n",
    "# Paso 4: Hacer predicciones en el conjunto de prueba\n",
    "y_pred = most_precise_model.predict(x_test)\n",
    "\n",
    "# Calcular la precisin del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisin del modelo en el conjunto de prueba: {:.2f}%\".format(accuracy*100))\n",
    "\n",
    "#filename = 'decision_tree_classifier_model.sav'\n",
    "#pickle.dump(most_precise_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've finally arrived at the end. As a reminder of what has been accomplished thus far:\n",
    "\n",
    "- We determined that logistic regression is the best model.\n",
    "\n",
    "- A logistic regression model was tweaked, trained on 31.000 data, and tested on the remaining 9000.\n",
    "\n",
    "- This part seeks to determine whether the preceding hypothesis of a common characteristic within the dataset is correct. How do we go about it? We do this by testing the model on a second fake news dataset to see if it produces the same results. The collection has only one limitation: it only contains bogus news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe\n",
    "fake_test = pd.read_csv(DATA_BASE_2_PATH + \"fake.csv\")\n",
    "\n",
    "# Adding classification column to identify fake-news\n",
    "fake_test['classification'] = 1\n",
    "\n",
    "# Selecting relevant columns with only english records\n",
    "fake_test = fake_test[['text', 'language', 'classification']]\n",
    "fake_test = fake_test.query(\"language == 'english'\")\n",
    "\n",
    "print(fake_test['text'])\n",
    "\n",
    "# Espliciting input and output variables\n",
    "fake_test['text'] = fake_test['text'].astype(str).apply(clean_text)\n",
    "fake_test['text'] = fake_test['text'].astype(str).apply(remove_stopwords)\n",
    "x_test = fake_test['text'].values.astype('U')\n",
    "y_test = fake_test['classification'].values.astype('U')\n",
    "\n",
    "# Classify new records\n",
    "predicted_LR_test = best_model.predict(x_test)\n",
    "\n",
    "# Print accuracy report\n",
    "print(classification_report(y_test, predicted_LR_test))\n",
    "accuracy = accuracy_score(y_test, predicted_LR_test)\n",
    "print(\"Precisin del modelo en un nuevo conjunto de prueba: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe\n",
    "test_data = pd.read_csv(DATA_BASE_2_PATH + \"train.csv\")\n",
    "\n",
    "# Selecting relevant columns with only english records\n",
    "test_data = test_data[['text', 'label']]\n",
    "\n",
    "# Espliciting input and output variables\n",
    "test_data['text'] = test_data['text'].astype(str).apply(clean_text)\n",
    "test_data['text'] = test_data['text'].astype(str).apply(remove_stopwords)\n",
    "x_test = test_data['text'].values.astype('U')\n",
    "y_test = test_data['label'].values.astype('U')\n",
    "\n",
    "# Classify new records\n",
    "predicted_LR_test = best_model.predict(x_test)\n",
    "\n",
    "# Print accuracy report\n",
    "print(classification_report(y_test, predicted_LR_test))\n",
    "accuracy = accuracy_score(y_test, predicted_LR_test)\n",
    "print(\"Precisin del modelo en un nuevo conjunto de prueba: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.02      0.03     10387\n",
      "           1       0.50      0.98      0.66     10413\n",
      "\n",
      "    accuracy                           0.50     20800\n",
      "   macro avg       0.47      0.50      0.35     20800\n",
      "weighted avg       0.47      0.50      0.35     20800\n",
      "\n",
      "Precisin del modelo en un nuevo conjunto de prueba: 49.82%\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframe\n",
    "test_data = pd.read_csv(DATA_BASE_2_PATH + \"train.csv\")\n",
    "\n",
    "# Selecting relevant columns with only english records\n",
    "test_data = test_data[['text', 'label']]\n",
    "\n",
    "# Espliciting input and output variables\n",
    "test_data['text'] = test_data['text'].astype(str).apply(clean_text)\n",
    "test_data['text'] = test_data['text'].astype(str).apply(remove_stopwords)\n",
    "x_test = test_data['text'].values.astype('U')\n",
    "y_test = test_data['label'].values.astype('U')\n",
    "\n",
    "# Classify new records\n",
    "predicted_LR_test = most_precise_model.predict(x_test)\n",
    "\n",
    "# Print accuracy report\n",
    "print(classification_report(y_test, predicted_LR_test))\n",
    "accuracy = accuracy_score(y_test, predicted_LR_test)\n",
    "print(\"Precisin del modelo en un nuevo conjunto de prueba: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   34,    42,   184,   235,   275,   354,   383,   406,   421,\n",
      "         441,   516,   634,   678,   788,   792,   795,   861,   884,\n",
      "         889,  1012,  1035,  1036,  1074,  1153,  1156,  1197,  1255,\n",
      "        1333,  1361,  1366,  1397,  1414,  1507,  1543,  1607,  1613,\n",
      "        1652,  1663,  1689,  1787,  1825,  1843,  1879,  1917,  1960,\n",
      "        2030,  2057,  2132,  2272,  2596,  2613,  2615,  2752,  2771,\n",
      "        2955,  2958,  2960,  3070,  3093,  3239,  3241,  3279,  3295,\n",
      "        3344,  3359,  3390,  3474,  3584,  3685,  3718,  3746,  3785,\n",
      "        3942,  3979,  3985,  4010,  4043,  4047,  4061,  4117,  4186,\n",
      "        4243,  4254,  4377,  4386,  4433,  4452,  4569,  4649,  4667,\n",
      "        4674,  4759,  4838,  4994,  5029,  5030,  5071,  5075,  5100,\n",
      "        5166,  5199,  5265,  5518,  5531,  5634,  5660,  5719,  5748,\n",
      "        5773,  5889,  5901,  5994,  6018,  6091,  6170,  6172,  6250,\n",
      "        6273,  6317,  6321,  6333,  6344,  6499,  6648,  6726,  6762,\n",
      "        6796,  6841,  6865,  7002,  7012,  7041,  7049,  7133,  7136,\n",
      "        7244,  7279,  7452,  7527,  7798,  7822,  7916,  8025,  8110,\n",
      "        8118,  8199,  8282,  8318,  8376,  8410,  8562,  8567,  8838,\n",
      "        8867,  8913,  8942,  8950,  8960,  9109,  9124,  9215,  9416,\n",
      "        9420,  9699,  9849,  9860,  9861,  9928,  9989, 10070, 10093,\n",
      "       10188, 10199, 10244, 10256, 10301, 10316, 10366, 10388, 10403,\n",
      "       10493, 10527, 10593, 10616, 10672, 10737, 10740, 10927, 10988,\n",
      "       11026, 11066, 11083, 11106, 11134, 11157, 11165, 11287, 11301,\n",
      "       11325, 11382, 11465, 11739, 11808, 11855, 12039, 12076, 12170,\n",
      "       12225, 12250, 12381, 12426, 12457, 12473, 12482, 12497, 12580,\n",
      "       12581, 12626, 12637, 12663, 12670, 12718, 12745, 12791, 12930,\n",
      "       12966, 13010, 13011, 13053, 13059, 13071, 13102, 13179, 13305,\n",
      "       13395, 13425, 13454, 13461, 13468, 13470, 13599, 13630, 13642,\n",
      "       13657, 13707, 13802, 13878, 13916, 14045, 14058, 14169, 14294,\n",
      "       14313, 14340, 14391, 14392, 14401, 14446, 14449, 14473, 14514,\n",
      "       14583, 14590, 14607, 14632, 14647, 14687, 14817, 14846, 14899,\n",
      "       14907, 14908, 14922, 14959, 15034, 15079, 15107, 15133, 15160,\n",
      "       15183, 15352, 15381, 15400, 15457, 15462, 15509, 15563, 15584,\n",
      "       15598, 15649, 15747, 15767, 15799, 15888, 15932, 15948, 16019,\n",
      "       16079, 16272, 16287, 16306, 16342, 16366, 16473, 16500, 16601,\n",
      "       16614, 16788, 16942, 16959, 17004, 17056, 17115, 17141, 17175,\n",
      "       17189, 17233, 17272, 17301, 17304, 17404, 17621, 17688, 17803,\n",
      "       17804, 17810, 17831, 17867, 17895, 17911, 17943, 17996, 18066,\n",
      "       18119, 18165, 18220, 18259, 18367, 18433, 18447, 18452, 18510,\n",
      "       18742, 18814, 18959, 18966, 18985, 18996, 19003, 19020, 19026,\n",
      "       19090, 19104, 19220, 19271, 19278, 19364, 19414, 19488, 19575,\n",
      "       19647, 19673, 19690, 19802, 19859, 19897, 19949, 19965, 20010,\n",
      "       20039, 20073, 20138, 20164, 20192, 20195, 20243, 20370, 20387,\n",
      "       20441, 20477, 20526, 20578, 20615, 20692, 20728, 20783, 20792,\n",
      "       20794]),)\n",
      "(array([    1,     5,     7, ..., 20795, 20796, 20797]),)\n"
     ]
    }
   ],
   "source": [
    "x = np.where(predicted_LR_test == '0')\n",
    "\n",
    "print(x)\n",
    "\n",
    "x = np.where(y_test == '0')\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There might be a number of reasons why a trained model is so accurate, especially in this scenario.\n",
    "\n",
    "- \"Overfitting\" is among them. Overfitting is likely to occur if the model classifies records extremely well within the same dataset but loses accuracy when deployed on fresh data.\n",
    "\n",
    "- A \"lucky pull\" might be another factor. If a model trains on the correct fraction of a dataset and is tested on easy-to-classify records, a fortunate pull may have occurred. Cross-validation, on the other hand, should eradicate the problem at its source.\n",
    "\n",
    "- A third explanation might be that the dataset shares a feature that external data does not. It is probable that all of the phony news in this dataset contains the term or the hashtag fake. It would be much easier for a model to understand truthful and fake news within the same dataset, but once presented with new data, accuracy might decrease.\n",
    "\n",
    "A common solution to all of the above would be to deploy the model on a different dataset and assess whether performance stays the same or decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As anticipated, the dataset only contained fake news, and the classifier correctly predicted each one of them, maintaining what had been promised during the tuning and testing phase. Our model classifies with 100% precision whether the news is fake or not, even with an external dataset with minimum computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, considering the algorithm has been deployed on a different dataset, the performance is more than satisfactory. It allows us to eliminate the overfitting and common feature hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
